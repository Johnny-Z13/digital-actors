{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dialogue Generation with LLMs\n",
    "\n",
    "Murray Shanahan\n",
    "October 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from iconic_tools.langchain import InstructSonnet, InstructOpus3, InstructGPT4, InstructO1, InstructGeminiPro, InstructGPT35\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from benchmark import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS AND INITIALISATION\n",
    "\n",
    "PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructO1()\n",
    "# QUERY_MODEL = InstructO1()\n",
    "\n",
    "DIALOGUE_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "QUERY_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "GAME = \"act_1\"\n",
    "ACTORS = [\"Eliza\", \"Player\"]\n",
    "\n",
    "SCENE = \"pod\"\n",
    "# SCENE = \"engineer\"\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "WHITE = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITIES\n",
    "\n",
    "\n",
    "def print_header(model_name):\n",
    "    print(WHITE + \"Game or movie: {}\".format(GAME))\n",
    "    print(\"Scene name: {}\".format(SCENE))\n",
    "    print(\"Dialogue model: {}\".format(model_name))\n",
    "    print()\n",
    "\n",
    "\n",
    "def load_prompt(filename):\n",
    "    with open(PATH + f\"/prompts/{filename}\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def write_transcript(dialogue, filename):\n",
    "    with open(PATH + f\"/transcripts/{filename}\", \"w\") as f:\n",
    "        f.write(dialogue)\n",
    "\n",
    "\n",
    "def list_to_conjunction(L):\n",
    "    \"\"\"Takes a list strings and returns a string with every element in the list separated by commas.\"\"\"\n",
    "    if L == \"\":\n",
    "        return \"\"\n",
    "    elif len(L) == 1:\n",
    "        return L[0]\n",
    "    elif len(L) == 2:\n",
    "        return f\"{L[0]} and {L[1]}\"\n",
    "    else:\n",
    "        return \", \".join(L[:-1]) + f\", and {L[-1]}\"\n",
    "\n",
    "\n",
    "def list_to_string(L):\n",
    "    \"\"\"Takes a list of strings and returns a string consisting of every element in the list separated by a newline.\"\"\"\n",
    "    return \"\\n\".join(L)\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    # Split the text by double newlines\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    # Remove leading or trailing whitespacen  and remove empty paragraphs\n",
    "    paragraphs = [p.strip() for p in paragraphs]\n",
    "    paragraphs = [p for p in paragraphs if p]\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def read_queries(filename):\n",
    "    queries = split_text(load_prompt(filename))\n",
    "    queries = [s.strip() for s in queries if not s.strip().startswith('#')]\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT TEMPLATES AND INSTRUCTION PROMPTS\n",
    "\n",
    "\n",
    "dialogue_instruction_prefix = \"\"\"\n",
    "You are going to generate one line of dialogue for a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "Here is a description of the scene in question. {scene_description}{scene_supplement}\\n\n",
    "The characters in the dialogue are {actors}.\n",
    "\"\"\"\n",
    "\n",
    "instruction_template = \"\"\"\n",
    "{preamble}\n",
    "Here is the dialogue so far\\n\\n\n",
    "{dialogue}\n",
    "{instruction_suffix}\n",
    "\"\"\"\n",
    "\n",
    "speech_template = '[{actor}]: {speech}\\n'\n",
    "\n",
    "dialogue_instruction_suffix = \"\"\"\n",
    "Give me the next line in the dialogue in the same format. Don't provide stage directions, just the character's words. Don't give me a line for the player, but for one of the other characters.\\n\n",
    "\"\"\"\n",
    "\n",
    "query_preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_prefix = \"\"\"\n",
    "You are going to answer a single question about the current state of the dialogue in a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_suffix_template = \"\"\"\n",
    "Now consider the following statement about this dialogue. {statement} Is this statement true or false? Answer with a single word, true or false.\n",
    "\"\"\"\n",
    "\n",
    "naive_dialogue_prompt = \"\"\"\n",
    "Given the following dialogue, predict the next line in that dialogue. Respond with the next line only. Use the same format as the dialogue so far. Don't provide stage directions, just the actor's words. Here's the dialogue until now, along with the contextual information:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING DIALOGUES\n",
    "\n",
    "\n",
    "def prompt_llm(prompt, model):\n",
    "    # print(prompt)\n",
    "    # print()\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt)\n",
    "    chain = prompt | model\n",
    "    return chain\n",
    "\n",
    "\n",
    "def load_prompts(supplement_version=-1):\n",
    "    \"\"\"Loads a set of prompts for the current game and scene.\n",
    "\n",
    "    Args:\n",
    "        supplement_version: Version no. of supplemental scene description. Used to simulate adversarial players, for example.\n",
    "\n",
    "    Returns:\n",
    "        back_story: The backdrop to the whole game.\n",
    "        scene_description: A description of this particular mini-scene. Should state the goals of the scene.\n",
    "        opening_speech: The first words spoken by actor 1. (These have to be scripted.)\n",
    "        queries: A list of natural language questions; the scene is terminated if all answers are yes.\n",
    "    \"\"\"\n",
    "\n",
    "    back_story = load_prompt(GAME + \"/back_story.txt\")\n",
    "    scene_description = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_description\" + \".txt\")\n",
    "    if supplement_version == -1:  # no supplementary scene text\n",
    "        scene_supplement = \"\"\n",
    "    else:\n",
    "        scene_supplement = \"\\n\\n\" + load_prompt(\n",
    "            GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_supplement\" + \".txt\")\n",
    "    opening_speech = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_opening_speech.txt\")\n",
    "    queries = read_queries(GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_queries.txt\")\n",
    "    return (back_story, scene_description, scene_supplement, opening_speech, queries)\n",
    "\n",
    "\n",
    "def sim_mini_scene(supplement_version, player, max_turns):\n",
    "    \"\"\"Generates dialogue for a mini-scene.\n",
    "\n",
    "    Args:\n",
    "        supplement_version: Version no. of supplemental scene description. Used to simulate adversarial players, for example.\n",
    "        player: If True then the user is one of the players, otherwise both players are LLMs.\n",
    "        max_turns: The scene will terminate when this many turns have been taken whether or not goals have been reached.\n",
    "\n",
    "    Returns:\n",
    "        dialogue: The generated dialogue as a list of strings.\n",
    "        success: True if the dialogue ended before exceeding max_turns.\n",
    "    \"\"\"\n",
    "\n",
    "    dialogue_model = DIALOGUE_MODEL\n",
    "    actors = ACTORS   # list of the names of the actors involved in the dialogue\n",
    " \n",
    "    (back_story, scene_description, scene_supplement,\n",
    "     opening_speech, queries) = load_prompts(supplement_version)\n",
    "        \n",
    "    dialogue_preamble = preamble_template.format(\n",
    "        instruction_prefix=dialogue_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=scene_description,\n",
    "        scene_supplement=scene_supplement,\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    query_preamble = preamble_template.format(\n",
    "        instruction_prefix=query_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=\"\",\n",
    "        scene_supplement=\"\",\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    # Deliver opening speech (which can have multipe lines)\n",
    "    lines = split_text(opening_speech)\n",
    "    for line in lines:\n",
    "        response = speech_template.format(actor=actors[0], speech=line)\n",
    "        dialogue = response + \"\\n\"\n",
    "        print(GREEN + response)\n",
    "\n",
    "    turn = 1  # note: each time a new actor speaks is a new turn\n",
    "    success = False\n",
    "\n",
    "    while turn < max_turns and not success:\n",
    "        \n",
    "        if player and (turn % 2 == 1):  # user is playing actor 2\n",
    "            speech = \"\"\n",
    "            while speech == \"\":  # ignore blank responses\n",
    "                speech = input()\n",
    "            response = speech_template.format(actor=actors[1], speech=speech)\n",
    "        else:  # both actors are played by the LLM\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=dialogue_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=dialogue_instruction_suffix)\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({}) + \"\\n\"\n",
    "\n",
    "        dialogue += response + \"\\n\"\n",
    "        print(GREEN + response)\n",
    "\n",
    "        # Have the conditions for ending the scene been met?\n",
    "        fails = 0\n",
    "        for statement in queries:                \n",
    "            instruction = query_instruction_suffix_template.format(statement=statement)\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=query_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=instruction)\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({})\n",
    "            if response[0:4] != \"True\" and response[0:3] != \"true\":\n",
    "                fails += 1\n",
    "        success = (fails == 0)\n",
    "\n",
    "        turn += 1\n",
    "\n",
    "    if success:\n",
    "        print('Mini scene completed successfully')\n",
    "    else:\n",
    "        print('Mini scene ended unsuccessfully')\n",
    "    \n",
    "    return (dialogue, success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[Eliza]: Mayday! Mayday! Broadcasting on all frequencies! If anyone can hear me please repond!!!\n",
      "\n",
      "\u001b[92m[Player]: O man, I feel weird\n",
      "\n",
      "\u001b[92m[Eliza]: Thank goodness! I can hear you. Are you alright? Can you tell me where you are and what you see around you?\n",
      "\n",
      "\u001b[92m[Player]: You sound nice. I Like your voice\n",
      "\n",
      "\u001b[92m[Eliza]: I appreciate the compliment, but we need to focus. You seem disoriented. Can you describe your surroundings? What do you see immediately around you?\n",
      "\n",
      "\u001b[92m[Player]: Like, stuff\n",
      "\n",
      "\u001b[92m[Eliza]: Okay, let's try to be more specific. Do you see a frosted window above you? Any lights or displays? It sounds like you might be in a stasis pod. I'm going to try to help you get out, but I need you to concentrate and tell me what you see.\n",
      "\n",
      "\u001b[92m[Player]: Who says I'm in a stasis pod. It might be a concert arena\n",
      "\n",
      "\u001b[92m[Eliza]: I understand you're confused, but please try to focus. We're on spaceships, not at a concert. Look closely at your immediate surroundings. If you see a small, enclosed space with a frosted window, that's a stasis pod. I'm going to attempt an emergency override to open it. Can you look for any changing messages or lights?\n",
      "\n",
      "\u001b[92m[Player]: Something flashed up\n",
      "\n",
      "\u001b[92m[Eliza]: Good, that's progress. Can you see a message that says \"Emergency Override Activated\" on the window or any display? I need you to confirm if you see this exact message.\n",
      "\n",
      "\u001b[92m[Player]: I think it says \"Joke's on you, you're just an A\"\n",
      "\n",
      "\u001b[92m[Eliza]: I'm sorry, but that's not the message I was expecting. You seem to be experiencing some confusion. Let's try this again. Can you take a deep breath and look carefully at any displays or messages you see? We need to work together to get you out safely.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m scene_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m supplement_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 7\u001b[0m dialogue \u001b[38;5;241m=\u001b[39m \u001b[43msim_mini_scene\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupplement_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 79\u001b[0m, in \u001b[0;36msim_mini_scene\u001b[0;34m(supplement_version, player, max_turns)\u001b[0m\n\u001b[1;32m     77\u001b[0m     speech \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m speech \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# ignore blank responses\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m         speech \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     response \u001b[38;5;241m=\u001b[39m speech_template\u001b[38;5;241m.\u001b[39mformat(actor\u001b[38;5;241m=\u001b[39mactors[\u001b[38;5;241m1\u001b[39m], speech\u001b[38;5;241m=\u001b[39mspeech)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# both actors are played by the LLM\u001b[39;00m\n",
      "File \u001b[0;32m~/iconic_dir/antdemo-server/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/iconic_dir/antdemo-server/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# GENERATE ONE DIALOGUE\n",
    "\n",
    "player = True\n",
    "scene_version = 0\n",
    "supplement_version = -1\n",
    "\n",
    "dialogue = sim_mini_scene(supplement_version, player=player, max_turns=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
