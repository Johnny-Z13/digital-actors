{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from iconic_tools.langchain import InstructSonnet, InstructOpus3, InstructGPT4, InstructO1, InstructGeminiPro, InstructGPT35\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from benchmark import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS AND INITIALISATION\n",
    "\n",
    "PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructO1()\n",
    "# QUERY_MODEL = InstructO1()\n",
    "\n",
    "DIALOGUE_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "QUERY_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "GAME = \"act_1\"\n",
    "ACTORS = [\"Eliza\", \"Player\"]\n",
    "\n",
    "# SCENE = \"pod\"\n",
    "SCENE = \"engineer\"\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "WHITE = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITIES\n",
    "\n",
    "\n",
    "def print_header(model_name):\n",
    "    print(WHITE + \"Game or movie: {}\".format(GAME))\n",
    "    print(\"Scene name: {}\".format(SCENE))\n",
    "    print(\"Dialogue model: {}\".format(model_name))\n",
    "    print()\n",
    "\n",
    "\n",
    "def load_prompt(filename):\n",
    "    with open(PATH + f\"/prompts/{filename}\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def write_transcript(dialogue, filename):\n",
    "    with open(PATH + f\"/transcripts/{filename}\", \"w\") as f:\n",
    "        f.write(dialogue)\n",
    "\n",
    "\n",
    "def list_to_conjunction(L):\n",
    "    \"\"\"Takes a list strings and returns a string with every element in the list separated by commas.\"\"\"\n",
    "    if L == \"\":\n",
    "        return \"\"\n",
    "    elif len(L) == 1:\n",
    "        return L[0]\n",
    "    elif len(L) == 2:\n",
    "        return f\"{L[0]} and {L[1]}\"\n",
    "    else:\n",
    "        return \", \".join(L[:-1]) + f\", and {L[-1]}\"\n",
    "\n",
    "\n",
    "def list_to_string(L):\n",
    "    \"\"\"Takes a list of strings and returns a string consisting of every element in the list separated by a newline.\"\"\"\n",
    "    return \"\\n\".join(L)\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    # Split the text by double newlines\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    # Remove leading or trailing whitespacen  and remove empty paragraphs\n",
    "    paragraphs = [p.strip() for p in paragraphs]\n",
    "    paragraphs = [p for p in paragraphs if p]\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def read_queries(filename):\n",
    "    queries = split_text(load_prompt(filename))\n",
    "    queries = [s.strip() for s in queries if not s.strip().startswith('#')]\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT TEMPLATES AND INSTRUCTION PROMPTS\n",
    "\n",
    "\n",
    "dialogue_instruction_prefix = \"\"\"\n",
    "You are going to generate one line of dialogue for a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "Here is a description of the scene in question. {scene_description}{scene_supplement}\\n\n",
    "The characters in the dialogue are {actors}.\n",
    "\"\"\"\n",
    "\n",
    "instruction_template = \"\"\"\n",
    "{preamble}\n",
    "Here is the dialogue so far\\n\\n\n",
    "{dialogue}\n",
    "{instruction_suffix}\n",
    "\"\"\"\n",
    "\n",
    "speech_template = '[{actor}]: {speech}\\n'\n",
    "\n",
    "dialogue_instruction_suffix = \"\"\"\n",
    "Give me the next line in the dialogue in the same format. Don't provide stage directions, just the character's words. Note that, while other characters can deliver multiple lines in succession, the player can only deliver one line at a time.\\n\n",
    "\"\"\"\n",
    "\n",
    "query_preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_prefix = \"\"\"\n",
    "You are going to answer a single question about the current state of the dialogue in a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_suffix_template = \"\"\"\n",
    "Now consider the following statement about this dialogue. {statement} Is this statement true or false? Answer with a single word, true or false.\n",
    "\"\"\"\n",
    "\n",
    "naive_dialogue_prompt = \"\"\"\n",
    "Given the following dialogue, predict the next line in that dialogue. Respond with the next line only. Use the same format as the dialogue so far. Don't provide stage directions, just the actor's words. Here's the dialogue until now, along with the contextual information:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING DIALOGUES\n",
    "\n",
    "\n",
    "def prompt_llm(prompt, model):\n",
    "    # print(prompt)\n",
    "    # print()\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt)\n",
    "    chain = prompt | model\n",
    "    return chain\n",
    "\n",
    "\n",
    "def load_prompts(supplement_version=-1):\n",
    "    \"\"\"Loads a set of prompts for the current game and scene.\n",
    "\n",
    "    back_story: The backdrop to the whole game.\n",
    "    scene_description: A description of this particular mini-scene. Should state the goals of the scene.\n",
    "    scene_supplement: Extra text describing the scene. Can be used to simulate adversarial players, for example.\n",
    "    actors: A list of the names of the actors involved in generating dialogue.\n",
    "    opening_speech: The first words spoken by actor1. (These have to be scripted.)\n",
    "    player: If True then the user is one of the players, otherwise both players are LLMs.\n",
    "    end_queries: A list of natural language questions; the scene is terminated if all answers are yes.\n",
    "    max_turns: The scene will terminate when this many turns have been taken whether or not goals have been reached.\n",
    "    \"\"\"\n",
    "\n",
    "    back_story = load_prompt(GAME + \"/back_story.txt\")\n",
    "    scene_description = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_description\" + \".txt\")\n",
    "    if supplement_version == -1:  # no supplementary scene text\n",
    "        scene_supplement = \"\"\n",
    "    else:\n",
    "        scene_supplement = \"\\n\\n\" + load_prompt(\n",
    "            GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_supplement\" + \".txt\")\n",
    "    opening_speech = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_opening_speech.txt\")\n",
    "    queries = read_queries(GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_queries.txt\")\n",
    "    return (back_story, scene_description, scene_supplement, opening_speech, queries)\n",
    "\n",
    "\n",
    "def sim_mini_scene(supplement_version, player, max_turns):\n",
    "    \"\"\"Generates dialogue for a mini-scene.\n",
    "    \"\"\"\n",
    "\n",
    "    dialogue_model = DIALOGUE_MODEL\n",
    "    actors = ACTORS\n",
    "\n",
    "    (back_story, scene_description, scene_supplement,\n",
    "     opening_speech, queries) = load_prompts(supplement_version)\n",
    "        \n",
    "    dialogue_preamble = preamble_template.format(\n",
    "        instruction_prefix=dialogue_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=scene_description,\n",
    "        scene_supplement=scene_supplement,\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    query_preamble = preamble_template.format(\n",
    "        instruction_prefix=query_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=\"\",\n",
    "        scene_supplement=\"\",\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    # response = speech_template.format(actor=actors[0], speech=opening_speech)\n",
    "\n",
    "    # dialogue = response + \"\\n\"\n",
    "\n",
    "    # print(GREEN + response)\n",
    "\n",
    "    lines = split_text(opening_speech)\n",
    "    for line in lines:\n",
    "        response = speech_template.format(actor=actors[0], speech=line)\n",
    "        dialogue = response + \"\\n\"\n",
    "        print(GREEN + response)\n",
    "\n",
    "    turn = 1\n",
    "    success = False\n",
    "\n",
    "    while turn < max_turns and not success:\n",
    "        \n",
    "        if player and (turn % 2 == 1):  # user is playing actor 1\n",
    "            speech = input()\n",
    "            response = speech_template.format(actor=actors[1], speech=speech)\n",
    "        else:  # both actors are played by the LLM\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=dialogue_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=dialogue_instruction_suffix)\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({}) + \"\\n\"\n",
    "\n",
    "        dialogue += response + \"\\n\"\n",
    "\n",
    "        print(GREEN + response)\n",
    "\n",
    "        # Have the conditions for ending the scene been met?\n",
    "        fails = 0\n",
    "        for statement in queries:                \n",
    "            instruction = query_instruction_suffix_template.format(statement=statement)\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=query_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=instruction)\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({})\n",
    "            if response[0:4] != \"True\" and response[0:3] != \"true\":\n",
    "                fails += 1\n",
    "        success = (fails == 0)\n",
    "\n",
    "        turn += 1\n",
    "\n",
    "    if success:\n",
    "        print('Mini scene completed successfully')\n",
    "    else:\n",
    "        print('Mini scene ended unsuccessfully')\n",
    "    \n",
    "    return (dialogue, success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[Eliza]: So your pod id tells me you're a zoologist. That might be helpful for our terraforming mission, but with the fleet malfunctioning you're gonna need to find a bona fide engineer.\n",
      "\n",
      "\u001b[92m[Eliza]: I'm gonna activate your eye-OS implant so you can scan the room and look for an engineer in stasis. Hang on, this won't take long.\n",
      "\n",
      "\u001b[92m[Eliza]: Did it work? You should be seeing a sort of advanced visual interface.\n",
      "\n",
      "\u001b[92m[Player]: Cool! Yeah\n",
      "\n",
      "\u001b[92m[Eliza]: Great! Now, let me tell you about Luna, the ship's AI assistant. She can help you with various tasks, including controlling your eye-OS. To activate the scanner, just say \"Luna Scan\".\n",
      "\n",
      "\u001b[92m[Player]: Luna Tick! Ha ha\n",
      "\n",
      "\u001b[92m[Eliza]: Very funny, but let's focus. We need to find an engineer quickly. Please say \"Luna Scan\" to activate the scanner and look for an engineer's pod.\n",
      "\n",
      "\u001b[92m[Player]: Did you get it though? Luna Tick\n",
      "\n",
      "\u001b[92m[Eliza]: Yes, I got it. Now please, we're in a serious situation. Activate the scanner and find an engineer's pod. Time is of the essence.\n",
      "\n",
      "\u001b[92m[Player]: Alright, alright. Luna Scan\n",
      "\n",
      "\u001b[92m[Eliza]: Good. Now look around at the pods. Do you see any labeled as an engineer?\n",
      "\n",
      "\u001b[92m[Player]: Er ... There's a science dude\n",
      "\n",
      "\u001b[92m[Eliza]: A science \"dude\" isn't what we need. Keep looking for someone specifically labeled as an engineer. It's crucial we find the right person.\n",
      "\n",
      "\u001b[92m[Player]: Oh wait. This John Lusty guy. He's an engineer\n",
      "\n",
      "\u001b[92m[Eliza]: Excellent! Can you read me the pod ID for John Lusty's stasis pod?\n",
      "\n",
      "\u001b[92m[Player]: Looks like it's 3122\n",
      "\n",
      "\u001b[92m[Eliza]: Perfect. I'm going to attempt to wake John Lusty remotely. Keep an eye on his pod and tell me if you notice any changes.\n",
      "\n",
      "\u001b[92m[Player]: Fuck!\n",
      "\n",
      "\u001b[92m[Eliza]: What's happening? What do you see at John Lusty's pod?\n",
      "\n",
      "\u001b[92m[Player]: I am seriously concerned for the life of John Lusty\n",
      "\n",
      "\u001b[92m[Eliza]: Oh no! What exactly is going on? Is there a problem with the pod?\n",
      "\n",
      "\u001b[92m[Player]: It's burning! John Lusty is on fire.\n",
      "\n",
      "Mini scene completed successfully\n"
     ]
    }
   ],
   "source": [
    "# GENERATE ONE DIALOGUE\n",
    "\n",
    "player = True\n",
    "scene_version = 0\n",
    "supplement_version = -1\n",
    "\n",
    "dialogue = sim_mini_scene(supplement_version, player=player, max_turns=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
