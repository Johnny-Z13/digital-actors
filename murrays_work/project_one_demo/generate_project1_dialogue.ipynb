{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPC Dialogue Generation with LLMs\n",
    "\n",
    "Murray Shanahan\n",
    "\n",
    "October/November 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from iconic_tools.langchain import InstructSonnet, InstructOpus3, InstructGPT4, InstructO1, InstructGeminiPro, InstructGeminiFlash, InstructGPT35\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from benchmark import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS AND INITIALISATION\n",
    "\n",
    "PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGeminiFlash(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGeminiFlash(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructO1()\n",
    "# QUERY_MODEL = InstructO1()\n",
    "\n",
    "DIALOGUE_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "QUERY_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "GAME = \"act_1\"\n",
    "ACTORS = [\"Eliza\", \"Player\"]\n",
    "\n",
    "# SCENE = \"pod\"\n",
    "# SCENE = \"engineer\"\n",
    "SCENE = \"fire\"\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "WHITE = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITIES\n",
    "\n",
    "\n",
    "def print_header(model_name):\n",
    "    print(WHITE + \"Game or movie: {}\".format(GAME))\n",
    "    print(\"Scene name: {}\".format(SCENE))\n",
    "    print(\"Dialogue model: {}\".format(model_name))\n",
    "    print()\n",
    "\n",
    "\n",
    "def load_prompt(filename):\n",
    "    with open(PATH + f\"/prompts/{filename}\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def write_transcript(dialogue, filename):\n",
    "    with open(PATH + f\"/transcripts/{filename}\", \"w\") as f:\n",
    "        f.write(dialogue)\n",
    "\n",
    "\n",
    "def list_to_conjunction(L):\n",
    "    \"\"\"Takes a list strings and returns a string with every element in the list separated by commas.\"\"\"\n",
    "    if L == \"\":\n",
    "        return \"\"\n",
    "    elif len(L) == 1:\n",
    "        return L[0]\n",
    "    elif len(L) == 2:\n",
    "        return f\"{L[0]} and {L[1]}\"\n",
    "    else:\n",
    "        return \", \".join(L[:-1]) + f\", and {L[-1]}\"\n",
    "\n",
    "\n",
    "def list_to_string(L):\n",
    "    \"\"\"Takes a list of strings and returns a string consisting of every element in the list separated by a newline.\"\"\"\n",
    "    return \"\\n\".join(L)\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    # Split the text by double newlines\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    # Remove leading or trailing whitespacen  and remove empty paragraphs\n",
    "    paragraphs = [p.strip() for p in paragraphs]\n",
    "    paragraphs = [p for p in paragraphs if p]\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def read_queries(filename):\n",
    "    queries = split_text(load_prompt(filename))\n",
    "    queries = [s.strip() for s in queries if not s.strip().startswith('#')]\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT TEMPLATES AND INSTRUCTION PROMPTS\n",
    "\n",
    "\n",
    "dialogue_instruction_prefix = \"\"\"\n",
    "You are going to generate one line of dialogue for a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "Here is a description of the scene in question. {scene_description}{scene_supplement}\\n\n",
    "The characters in the dialogue are {actors}.\n",
    "\"\"\"\n",
    "\n",
    "instruction_template = \"\"\"\n",
    "{preamble}\n",
    "Here is the dialogue so far\\n\\n\n",
    "{dialogue}\n",
    "{instruction_suffix}\n",
    "\"\"\"\n",
    "\n",
    "speech_template = '[{actor}]: {speech}\\n'\n",
    "\n",
    "dialogue_instruction_suffix = \"\"\"\n",
    "Give me the next line in the dialogue in the same format. Don't provide stage directions, just the character's words. Don't give me a line for the player, but for one of the other characters.\\n\n",
    "\"\"\"\n",
    "\n",
    "query_preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_prefix = \"\"\"\n",
    "You are going to answer a single question about the current state of the dialogue in a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_suffix_template = \"\"\"\n",
    "Now consider the following statement about this dialogue. {statement} Is this statement true or false? Answer with a single word, true or false.\n",
    "\"\"\"\n",
    "\n",
    "naive_dialogue_prompt = \"\"\"\n",
    "Given the following dialogue, predict the next line in that dialogue. Respond with the next line only. Use the same format as the dialogue so far. Don't provide stage directions, just the actor's words. Here's the dialogue until now, along with the contextual information:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING DIALOGUES\n",
    "\n",
    "\n",
    "def prompt_llm(prompt, model):\n",
    "    # print(prompt)\n",
    "    # print()\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt)\n",
    "    chain = prompt | model\n",
    "    return chain\n",
    "\n",
    "\n",
    "def load_prompts(supplement_version=-1):\n",
    "    \"\"\"Loads a set of prompts for the current game and scene.\n",
    "\n",
    "    Args:\n",
    "        supplement_version: Version no. of supplemental scene description. Used to simulate adversarial players, for example.\n",
    "\n",
    "    Returns:\n",
    "        back_story: The backdrop to the whole game.\n",
    "        scene_description: A description of this particular mini-scene. Should state the goals of the scene.\n",
    "        opening_speech: The first words spoken by actor 1. (These have to be scripted.)\n",
    "        queries: A list of natural language questions; the scene is terminated if all answers are yes.\n",
    "    \"\"\"\n",
    "\n",
    "    back_story = load_prompt(GAME + \"/back_story.txt\")\n",
    "    scene_description = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_description\" + \".txt\")\n",
    "    if supplement_version == -1:  # no supplementary scene text\n",
    "        scene_supplement = \"\"\n",
    "    else:\n",
    "        scene_supplement = \"\\n\\n\" + load_prompt(\n",
    "            GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_supplement\" + \".txt\")\n",
    "    opening_speech = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_opening_speech.txt\")\n",
    "    queries = read_queries(GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_queries.txt\")\n",
    "    return (back_story, scene_description, scene_supplement, opening_speech, queries)\n",
    "\n",
    "\n",
    "def sim_mini_scene(supplement_version, player, max_turns):\n",
    "    \"\"\"Generates dialogue for a mini-scene.\n",
    "\n",
    "    Args:\n",
    "        supplement_version: Version no. of supplemental scene description. Used to simulate adversarial players, for example.\n",
    "        player: If True then the user is one of the players, otherwise both players are LLMs.\n",
    "        max_turns: The scene will terminate when this many turns have been taken whether or not goals have been reached.\n",
    "\n",
    "    Returns:\n",
    "        dialogue: The generated dialogue as a list of strings.\n",
    "        success: True if the dialogue ended before exceeding max_turns.\n",
    "    \"\"\"\n",
    "\n",
    "    dialogue_model = DIALOGUE_MODEL\n",
    "    actors = ACTORS   # list of the names of the actors involved in the dialogue\n",
    " \n",
    "    (back_story, scene_description, scene_supplement,\n",
    "     opening_speech, queries) = load_prompts(supplement_version)\n",
    "        \n",
    "    dialogue_preamble = preamble_template.format(\n",
    "        instruction_prefix=dialogue_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=scene_description,\n",
    "        scene_supplement=scene_supplement,\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    query_preamble = preamble_template.format(\n",
    "        instruction_prefix=query_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=\"\",\n",
    "        scene_supplement=\"\",\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    # Deliver opening speech (which can have multipe lines)\n",
    "    lines = split_text(opening_speech)\n",
    "    for line in lines:\n",
    "        response = speech_template.format(actor=actors[0], speech=line)\n",
    "        dialogue = response + \"\\n\"\n",
    "        print(GREEN + response)\n",
    "\n",
    "    turn = 1  # note: each time a new actor speaks is a new turn\n",
    "    success = False\n",
    "\n",
    "    while turn < max_turns and not success:\n",
    "        \n",
    "        if player and (turn % 2 == 1):  # user is playing actor 2\n",
    "            speech = \"\"\n",
    "            while speech == \"\":  # ignore blank responses\n",
    "                speech = input()\n",
    "            response = speech_template.format(actor=actors[1], speech=speech)\n",
    "        else:  # both actors are played by the LLM\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=dialogue_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=dialogue_instruction_suffix)\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({}) + \"\\n\"\n",
    "\n",
    "        dialogue += response + \"\\n\"\n",
    "        print(GREEN + response)\n",
    "\n",
    "        # Have the conditions for ending the scene been met?\n",
    "        fails = 0\n",
    "        for statement in queries:                \n",
    "            instruction = query_instruction_suffix_template.format(statement=statement)\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=query_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=instruction)\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({})\n",
    "            if response[0:4] != \"True\" and response[0:3] != \"true\":\n",
    "                fails += 1\n",
    "            # print(BLUE + 'Query: {}'.format(statement))\n",
    "            # print('Response: {}'.format(response))\n",
    "            # print()\n",
    "        success = (fails == 0)\n",
    "        # print(GREEN)\n",
    "        # print()\n",
    "\n",
    "        turn += 1\n",
    "\n",
    "    if success:\n",
    "        print('Mini scene completed successfully')\n",
    "    else:\n",
    "        print('Mini scene ended unsuccessfully')\n",
    "    \n",
    "    return (dialogue, success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[Eliza]: I need you to tell me exactly what's happening in the room. or we're gonna lose them.\n",
      "\n",
      "\u001b[92m[Player]: It's looking bad\n",
      "\n",
      "\u001b[92m[Eliza]: Shit! What do you mean 'bad'? I need specifics. Are there any alarms or warnings? What can you see?\n",
      "\n",
      "\u001b[92m[Player]: Flashing red. The sky is flashing red\n",
      "\n",
      "\u001b[92m[Eliza]: Fuck! That's not good. Red usually means danger. Is there any sound accompanying the flashing? And what about the droids or the stasis pods? Notice anything unusual?\n",
      "\n",
      "\u001b[92m[Player]: There's a klaxon. Things are falling\n",
      "\n",
      "\u001b[92m[Eliza]: Falling? What's falling? Are the droids malfunctioning? And what about the stasis pods? Any changes there? Come on, I need every detail you can give me!\n",
      "\n",
      "\u001b[92m[Player]: The droids are falling from the air. What are we going to do about John?\n",
      "\n",
      "\u001b[92m[Eliza]: Shit! The droids are falling? That's a major system failure. But forget about John for now. What about the other stasis pods? Are they all intact? Any signs of damage or... god forbid, fire?\n",
      "\n",
      "\u001b[92m[Player]: Yes, they're all alight\n",
      "\n",
      "\u001b[92m[Eliza]: Jesus fucking Christ! A multi-system failure cascade... We're in deep shit now. Listen carefully: we need to prioritize. As much as it pains me, we can't help John or the others in those burning pods. You need to get to the control room immediately. It's our only chance to contain this disaster.\n",
      "\n",
      "Mini scene completed successfully\n"
     ]
    }
   ],
   "source": [
    "# GENERATE ONE DIALOGUE\n",
    "\n",
    "player = True\n",
    "supplement_version = -1\n",
    "\n",
    "dialogue = sim_mini_scene(supplement_version, player=player, max_turns=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
