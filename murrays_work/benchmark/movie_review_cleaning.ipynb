{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files into DataFrames\n",
    "dataset_df = pd.read_csv(\"dataset/task_dataset.csv\")\n",
    "reviews_df = pd.read_csv(\"movie_reviews.csv\")\n",
    "\n",
    "# Perform an inner join on the 'title' column\n",
    "filtered_reviews_df = reviews_df[reviews_df['title'].isin(dataset_df['title'])]\n",
    "\n",
    "# Reset the index of the filtered DataFrame\n",
    "filtered_reviews_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Load indices to keep from file if it exists\n",
    "indices_file = \"indices_to_keep.json\"\n",
    "if os.path.exists(indices_file):\n",
    "    with open(indices_file, \"r\") as file:\n",
    "        indices_to_keep = json.load(file)\n",
    "else:\n",
    "    indices_to_keep = []\n",
    "\n",
    "# Manually review each row starting from the last reviewed index\n",
    "start_index = max(indices_to_keep) + 1 if indices_to_keep else 0\n",
    "for index in range(start_index, len(filtered_reviews_df)):\n",
    "    row = filtered_reviews_df.iloc[index]\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"Review: {row['review']}\")\n",
    "    print(f\"Score: {row['score']}\")\n",
    "    keep = input(\"Keep this review? (y/n): \").strip().lower()\n",
    "    print('Answer:', keep)\n",
    "    if keep == 'y':\n",
    "        indices_to_keep.append(index)\n",
    "    \n",
    "    # Save the current state to file\n",
    "    with open(indices_file, \"w\") as file:\n",
    "        json.dump(indices_to_keep, file)\n",
    "\n",
    "# Filter the DataFrame to keep only the selected rows\n",
    "final_reviews_df = filtered_reviews_df.loc[indices_to_keep]\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of removed reviews\n",
    "Review: Emmerich favours hoisting his camera high and dry to give audiences the best panoramic view, but it removes all tension from proceedings - you're always at a safe distance.\n",
    "Review: The Abyss is an exercise in experimental and rogue filmmaking that is perhaps one of Cameron's most well known signatures.\n",
    "Review: Villeneuve sets a new standard for big-budget, premium-format-ready filmmaking, delivering an aesthetic masterwork that shames its peers.\n",
    "Review: It's very well done, with some spectacular overhead shots — whether from helicopters or drones is hard to say these days — that convey brilliantly the nightmare of what it must be like to be stranded at sea.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "dataset_df = pd.read_csv(\"dataset/task_dataset.csv\")\n",
    "reviews_df = pd.read_csv(\"movie_reviews.csv\")\n",
    "\n",
    "# Perform an inner join on the 'title' column\n",
    "filtered_reviews_df = reviews_df[reviews_df['title'].isin(dataset_df['title'])]\n",
    "\n",
    "# Reset the index of the filtered DataFrame\n",
    "filtered_reviews_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Load indices to keep from file if it exists\n",
    "indices_file = \"indices_to_keep.json\"\n",
    "if os.path.exists(indices_file):\n",
    "    with open(indices_file, \"r\") as file:\n",
    "        indices_to_keep = json.load(file)\n",
    "else:\n",
    "    indices_to_keep = []\n",
    "\n",
    "# Filter out invalid reviews\n",
    "valid_reviews_df = filtered_reviews_df[\n",
    "    ~filtered_reviews_df['review'].isna() &\n",
    "    (filtered_reviews_df['review'].str.lower() != 'nan') &\n",
    "    (filtered_reviews_df['review'] != 'Click here to read review')\n",
    "]\n",
    "\n",
    "# Calculate the percentage of valid reviews that were selected\n",
    "valid_indices_to_keep = [index for index in indices_to_keep if index in valid_reviews_df.index]\n",
    "percentage_selected = (len(valid_indices_to_keep) / len(valid_reviews_df)) * 100\n",
    "\n",
    "print(f\"Percentage of valid reviews selected: {percentage_selected:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "dataset_df = pd.read_csv(\"dataset/task_dataset.csv\")\n",
    "reviews_df = pd.read_csv(\"movie_reviews.csv\")\n",
    "\n",
    "# Perform an inner join on the 'title' column\n",
    "filtered_reviews_df = reviews_df[reviews_df['title'].isin(dataset_df['title'])]\n",
    "\n",
    "# Reset the index of the filtered DataFrame\n",
    "filtered_reviews_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Load indices to keep from file if it exists\n",
    "indices_file = \"indices_to_keep.json\"\n",
    "if os.path.exists(indices_file):\n",
    "    with open(indices_file, \"r\") as file:\n",
    "        indices_to_keep = json.load(file)\n",
    "else:\n",
    "    indices_to_keep = []\n",
    "\n",
    "# Filter out invalid reviews\n",
    "valid_reviews_df = filtered_reviews_df[\n",
    "    ~filtered_reviews_df['review'].isna() &\n",
    "    (filtered_reviews_df['review'].str.lower() != '<nan>') &\n",
    "    (filtered_reviews_df['review'] != 'Click here to read review')\n",
    "]\n",
    "\n",
    "# Create a mapping from the original indices to the new indices\n",
    "index_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(valid_reviews_df.index)}\n",
    "\n",
    "# Map the indices to keep to the new indices\n",
    "valid_indices_to_keep = [index_mapping[idx] for idx in indices_to_keep if idx in index_mapping]\n",
    "\n",
    "# Filter the DataFrame to keep only the selected rows\n",
    "final_reviews_df = valid_reviews_df.iloc[valid_indices_to_keep]\n",
    "\n",
    "# Calculate the average scores per title for the original DataFrame\n",
    "original_avg_scores = valid_reviews_df.groupby('title')['score'].mean().reset_index()\n",
    "original_avg_scores.columns = ['title', 'original_avg_score',]\n",
    "\n",
    "# Calculate the average scores per title for the filtered DataFrame\n",
    "filtered_avg_scores = final_reviews_df.groupby('title')['score'].mean().reset_index()\n",
    "filtered_avg_scores.columns = ['title', 'filtered_avg_score']\n",
    "\n",
    "# Merge the original and filtered average scores\n",
    "comparison_df = pd.merge(original_avg_scores, filtered_avg_scores, on='title', how='left')\n",
    "\n",
    "# Calculate the change in average scores\n",
    "comparison_df['score_change'] = comparison_df['filtered_avg_score'] - comparison_df['original_avg_score']\n",
    "\n",
    "# Calculate the average score change and its standard deviation\n",
    "average_score_change = comparison_df['score_change'].mean()\n",
    "std_score_change = comparison_df['score_change'].std()\n",
    "\n",
    "# Display the comparison DataFrame and the statistics\n",
    "print(comparison_df)\n",
    "print(f\"Average score change: {average_score_change:.3f}\")\n",
    "print(f\"Standard deviation of score change: {std_score_change:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           title   genre  score_critic  task_idx  \\\n",
      "0                      127 HOURS   Drama      0.723889         1   \n",
      "1                      127 HOURS   Drama      0.723889         1   \n",
      "2                      127 HOURS   Drama      0.723889         1   \n",
      "3                           2012  Action      0.527083         9   \n",
      "4                           2012  Action      0.527083         9   \n",
      "..                           ...     ...           ...       ...   \n",
      "88                      THE CROW  Action      0.461111         2   \n",
      "89                      THE CROW  Action      0.461111         2   \n",
      "90  The Abyss - by James Cameron  Sci-Fi      0.792500         3   \n",
      "91  The Abyss - by James Cameron  Sci-Fi      0.792500         3   \n",
      "92  The Abyss - by James Cameron  Sci-Fi      0.792500         3   \n",
      "\n",
      "             task  score_metric  exec_seconds  precision  synergy  \\\n",
      "0      scene_size      0.166667     22.696968        0.0      0.0   \n",
      "1      scene_size      0.125000    118.440939        0.0      0.0   \n",
      "2      scene_size      0.458333     56.093381        1.0      0.0   \n",
      "3   interactivity      0.933333    503.708321        1.0      1.0   \n",
      "4   interactivity      0.875000    296.949809        1.0      1.0   \n",
      "..            ...           ...           ...        ...      ...   \n",
      "88     scene_size      0.444444    107.304317        1.0      0.5   \n",
      "89     scene_size      0.555556     70.977372        1.0      0.5   \n",
      "90     scene_size      0.611111     32.810779        1.0      0.5   \n",
      "91     scene_size      0.472222    703.782246        0.0      1.0   \n",
      "92     scene_size      0.277778     51.970644        0.0      0.5   \n",
      "\n",
      "    impersonation_ARNOLD  ...  impersonation_Murph  impersonation_Dean  \\\n",
      "0                    NaN  ...                  NaN                 NaN   \n",
      "1                    NaN  ...                  NaN                 NaN   \n",
      "2                    NaN  ...                  NaN                 NaN   \n",
      "3                    NaN  ...                  NaN                 NaN   \n",
      "4                    NaN  ...                  NaN                 NaN   \n",
      "..                   ...  ...                  ...                 ...   \n",
      "88                   NaN  ...                  NaN                 NaN   \n",
      "89                   NaN  ...                  NaN                 NaN   \n",
      "90                   NaN  ...                  NaN                 NaN   \n",
      "91                   NaN  ...                  NaN                 NaN   \n",
      "92                   NaN  ...                  NaN                 NaN   \n",
      "\n",
      "    impersonation_Joan  impersonation_Ronald  impersonation_Tim  \\\n",
      "0                  NaN                   NaN                NaN   \n",
      "1                  NaN                   NaN                NaN   \n",
      "2                  NaN                   NaN                NaN   \n",
      "3                  NaN                   NaN                NaN   \n",
      "4                  NaN                   NaN                NaN   \n",
      "..                 ...                   ...                ...   \n",
      "88                 NaN                   NaN                NaN   \n",
      "89                 NaN                   NaN                NaN   \n",
      "90                 NaN                   NaN                NaN   \n",
      "91                 NaN                   NaN                NaN   \n",
      "92                 NaN                   NaN                NaN   \n",
      "\n",
      "    impersonation_Bill  impersonation_Grant  impersonation_Starla  \\\n",
      "0                  NaN                  NaN                   NaN   \n",
      "1                  NaN                  NaN                   NaN   \n",
      "2                  NaN                  NaN                   NaN   \n",
      "3                  NaN                  NaN                   NaN   \n",
      "4                  NaN                  NaN                   NaN   \n",
      "..                 ...                  ...                   ...   \n",
      "88                 NaN                  NaN                   NaN   \n",
      "89                 NaN                  NaN                   NaN   \n",
      "90                 NaN                  NaN                   NaN   \n",
      "91                 NaN                  NaN                   NaN   \n",
      "92                 NaN                  NaN                   NaN   \n",
      "\n",
      "    impersonation_Wally              llm  \n",
      "0                   NaN    baseline gpt4  \n",
      "1                   NaN  baseline sonnet  \n",
      "2                   NaN  baseline gemini  \n",
      "3                   NaN    baseline gpt4  \n",
      "4                   NaN  baseline sonnet  \n",
      "..                  ...              ...  \n",
      "88                  NaN  baseline sonnet  \n",
      "89                  NaN  baseline gemini  \n",
      "90                  NaN    baseline gpt4  \n",
      "91                  NaN  baseline sonnet  \n",
      "92                  NaN  baseline gemini  \n",
      "\n",
      "[93 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          sum_sq     df         F    PR(>F)\n",
      "C(score_type)           0.231603    1.0  6.818545  0.009800\n",
      "C(genre)                1.220354    4.0  8.982019  0.000001\n",
      "C(score_type):C(genre)  0.764897    4.0  5.629779  0.000275\n",
      "Residual                5.978117  176.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Merge critic and metric scores into a single column and differentiate them with a \"type\" column\n",
    "df_long = pd.melt(merged_df, id_vars=[\"title\", \"genre\"], \n",
    "                  value_vars=[\"score_critic\", \"score_metric\"], \n",
    "                  var_name=\"score_type\", value_name=\"score\")\n",
    "\n",
    "# Run a two-way ANOVA to test if genre has an effect on scores\n",
    "# Create the formula for the ANOVA test: score ~ score_type * genre\n",
    "model = ols('score ~ C(score_type) * C(genre)', data=df_long).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations by Genre:\n",
      "    genre  correlation   z_score   p_value   n\n",
      "0   Drama     0.849371  1.253890  0.000062  15\n",
      "4  Horror     0.371471  0.390128  0.172797  15\n",
      "3  Comedy     0.008082  0.008082  0.972265  21\n",
      "1  Action    -0.086514 -0.086731  0.732850  18\n",
      "2  Sci-Fi    -0.325561 -0.337855  0.120562  24\n",
      "\n",
      "Strongest correlation: Drama (r = 0.849, p = 0.000, n = 15)\n",
      "Weakest correlation: Sci-Fi (r = -0.326, p = 0.121, n = 24)\n",
      "\n",
      "Action correlation: -0.087\n",
      "Drama correlation: 0.849\n",
      "The hypothesis that action movies have a lower correlation between actor performance and critic reviews compared to drama is supported by this data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming merged_df is already created as per your previous code\n",
    "\n",
    "# Step 1: Calculate correlation coefficients for each genre\n",
    "def fisher_z(r):\n",
    "    return 0.5 * np.log((1 + r) / (1 - r))\n",
    "\n",
    "genre_correlations = []\n",
    "genres = merged_df['genre'].unique()\n",
    "\n",
    "for genre in genres:\n",
    "    genre_data = merged_df[merged_df['genre'] == genre]\n",
    "    r, p = stats.pearsonr(genre_data['score_critic'], genre_data['score_metric'])\n",
    "    z = fisher_z(r)\n",
    "    n = len(genre_data)\n",
    "    genre_correlations.append({\n",
    "        'genre': genre, \n",
    "        'correlation': r, \n",
    "        'z_score': z, \n",
    "        'p_value': p,\n",
    "        'n': n\n",
    "    })\n",
    "\n",
    "correlation_df = pd.DataFrame(genre_correlations)\n",
    "\n",
    "# Sort by correlation strength\n",
    "correlation_df = correlation_df.sort_values('correlation', ascending=False)\n",
    "\n",
    "# Print correlations for each genre\n",
    "print(\"Correlations by Genre:\")\n",
    "print(correlation_df)\n",
    "\n",
    "# Identify genres with strongest and weakest correlations\n",
    "strongest = correlation_df.iloc[0]\n",
    "weakest = correlation_df.iloc[-1]\n",
    "\n",
    "print(f\"\\nStrongest correlation: {strongest['genre']} (r = {strongest['correlation']:.3f}, p = {strongest['p_value']:.3f}, n = {strongest['n']})\")\n",
    "print(f\"Weakest correlation: {weakest['genre']} (r = {weakest['correlation']:.3f}, p = {weakest['p_value']:.3f}, n = {weakest['n']})\")\n",
    "\n",
    "# Check if the hypothesis about action movies is supported\n",
    "action_corr = correlation_df[correlation_df['genre'] == 'Action']['correlation'].values[0]\n",
    "drama_corr = correlation_df[correlation_df['genre'] == 'Drama']['correlation'].values[0]\n",
    "\n",
    "print(f\"\\nAction correlation: {action_corr:.3f}\")\n",
    "print(f\"Drama correlation: {drama_corr:.3f}\")\n",
    "\n",
    "if action_corr < drama_corr:\n",
    "    print(\"The hypothesis that action movies have a lower correlation between actor performance and critic reviews compared to drama is supported by this data.\")\n",
    "else:\n",
    "    print(\"The hypothesis is not supported by this data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed correlation: 0.849\n",
      "Sample size: 15\n",
      "Actual power: 1.000\n",
      "Required sample size for power of 0.8: 4\n",
      "We have enough data to be confident in the correlation estimate for Drama.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.power import TTestPower\n",
    "\n",
    "# Parameters\n",
    "drama_data = correlation_df[correlation_df['genre'] == 'Drama'].iloc[0]\n",
    "alpha = 0.05  # Significance level\n",
    "power = 0.8   # Desired power level\n",
    "r = drama_data['correlation']  # Observed correlation for Drama\n",
    "n = drama_data['n']        # Sample size for Drama\n",
    "\n",
    "# Convert correlation to Cohen's d\n",
    "d = 2 * r / np.sqrt(1 - r**2)\n",
    "\n",
    "# Perform power analysis\n",
    "analysis = TTestPower()\n",
    "actual_power = analysis.solve_power(effect_size=d, nobs=n, alpha=alpha, power=None)\n",
    "required_n = analysis.solve_power(effect_size=d, nobs=None, alpha=alpha, power=power)\n",
    "\n",
    "print(f\"Observed correlation: {r:.3f}\")\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"Actual power: {actual_power:.3f}\")\n",
    "print(f\"Required sample size for power of {power}: {np.ceil(required_n):.0f}\")\n",
    "\n",
    "# Check if we have enough data\n",
    "if actual_power >= power:\n",
    "    print(\"We have enough data to be confident in the correlation estimate for Drama.\")\n",
    "else:\n",
    "    print(\"We do not have enough data to be confident in the correlation estimate for Drama.\")\n",
    "    print(f\"We need approximately {np.ceil(required_n) - n:.0f} more samples to reach the desired power.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation for Drama: 0.8494\n",
      "Current sample size: 15\n",
      "Achieved power: 1.0000\n",
      "Required sample size for 0.9 power: 10\n",
      "\n",
      "The current sample size is sufficient to detect the observed effect with the desired power.\n",
      "\n",
      "95% Confidence Interval for the correlation: (0.5968, 0.9488)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\borru\\LocalStudios\\DigitialActorsBenchmark\\env1\\Lib\\site-packages\\statsmodels\\stats\\power.py:524: ConvergenceWarning: \n",
      "Failed to converge on a solution.\n",
      "\n",
      "  warnings.warn(convergence_doc, ConvergenceWarning)\n",
      "C:\\Users\\borru\\AppData\\Local\\Temp\\ipykernel_18668\\4204434704.py:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(f\"Required sample size for {power:.1f} power: {int(np.ceil(required_n))}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "from scipy import stats\n",
    "\n",
    "# Extract data for Drama from correlation_df\n",
    "drama_data = correlation_df[correlation_df['genre'] == 'Drama'].iloc[0]\n",
    "r = drama_data['correlation']\n",
    "n = drama_data['n']\n",
    "\n",
    "# Set parameters\n",
    "alpha = 0.05  # Significance level\n",
    "power = 0.8   # Desired power level\n",
    "alternative = 'two-sided'  # Testing for both positive and negative correlations\n",
    "\n",
    "# Convert correlation to Fisher's z\n",
    "z = np.arctanh(r)\n",
    "\n",
    "# Calculate standard error of z\n",
    "se = 1 / np.sqrt(n - 3)\n",
    "\n",
    "# Calculate effect size (Cohen's d) for the correlation\n",
    "d = z / se\n",
    "\n",
    "# Perform power analysis\n",
    "power_analysis = NormalIndPower()\n",
    "\n",
    "# Calculate achieved power\n",
    "achieved_power = power_analysis.solve_power(effect_size=d, nobs1=n, alpha=alpha, alternative=alternative)\n",
    "\n",
    "# Calculate required sample size for desired power\n",
    "required_n = power_analysis.solve_power(effect_size=d, power=power, alpha=alpha, alternative=alternative)\n",
    "\n",
    "print(f\"Correlation for Drama: {r:.4f}\")\n",
    "print(f\"Current sample size: {n}\")\n",
    "print(f\"Achieved power: {achieved_power:.4f}\")\n",
    "print(f\"Required sample size for {power:.1f} power: {int(np.ceil(required_n))}\")\n",
    "\n",
    "# Check if current sample size is sufficient\n",
    "if achieved_power >= power:\n",
    "    print(\"\\nThe current sample size is sufficient to detect the observed effect with the desired power.\")\n",
    "else:\n",
    "    print(\"\\nThe current sample size is not sufficient to detect the observed effect with the desired power.\")\n",
    "    print(f\"You would need approximately {int(np.ceil(required_n)) - n} more samples to achieve the desired power.\")\n",
    "\n",
    "# Calculate confidence interval for the correlation\n",
    "z_score = stats.norm.ppf((1 + 0.95) / 2)\n",
    "margin_of_error = z_score * (1 / np.sqrt(n - 3))\n",
    "ci_lower = np.tanh(np.arctanh(r) - margin_of_error)\n",
    "ci_upper = np.tanh(np.arctanh(r) + margin_of_error)\n",
    "\n",
    "print(f\"\\n95% Confidence Interval for the correlation: ({ci_lower:.4f}, {ci_upper:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
