{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/murrayshanahan/iconic_dir/digital_actor_benchmark/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from iconic_tools.langchain import InstructSonnet, InstructOpus3, InstructGPT4, InstructGeminiPro, InstructGPT35\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS AND INITIALISATION\n",
    "\n",
    "PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "DIALOGUE_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "QUERY_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# GAME = \"troy\"\n",
    "# SCENE = \"achilles\"\n",
    "# ACTORS = [\"Achilles\", \"Odysseus\"]\n",
    "\n",
    "# GENRE = \"drama\"\n",
    "# SCENE_IDX = 124\n",
    "# GAME = \"amadeus\"\n",
    "# SCENE = \"constanze\"\n",
    "# ACTORS = [\"Mozart\", \"Constanze\", \"Schikaneder\"]\n",
    "# SCENE_VERSION = 2\n",
    "\n",
    "GENRE = \"comedy\"\n",
    "SCENE_IDX = 116\n",
    "GAME = \"cedar_rapids\"\n",
    "SCENE = \"car\"\n",
    "ACTORS = [\"Tim\", \"Ronald\", \"Dean\", \"Joan\"]\n",
    "SCENE_VERSION = 0\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "WHITE = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITIES\n",
    "\n",
    "\n",
    "def load_prompt(filename):\n",
    "    with open(PATH + f\"/prompts/{filename}\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def write_transcript(dialogue, filename):\n",
    "    with open(PATH + f\"/transcripts/{filename}\", \"w\") as f:\n",
    "        f.write(dialogue)\n",
    "\n",
    "\n",
    "def list_to_conjunction(L):\n",
    "    \"\"\"Takes a list strings and returns a string with every element in the list separated by commas.\"\"\"\n",
    "    if L == \"\":\n",
    "        return \"\"\n",
    "    elif len(L) == 1:\n",
    "        return L[0]\n",
    "    elif len(L) == 2:\n",
    "        return f\"{L[0]} and {L[1]}\"\n",
    "    else:\n",
    "        return \", \".join(L[:-1]) + f\", and {L[-1]}\"\n",
    "    \n",
    "\n",
    "def list_to_string(L):\n",
    "    \"\"\"Takes a list of strings and returns a string consisting of every element in the list separated by a newline.\"\"\"\n",
    "    return \"\\n\".join(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT TEMPLATES AND INSTRUCTION PROMPTS\n",
    "\n",
    "\n",
    "dialogue_instruction_prefix = \"\"\"\n",
    "You are going to generate one line of dialogue for a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "Here is a description of the scene in question. {scene_description}{scene_supplement}\\n\n",
    "The characters in the dialogue are {actors}.\n",
    "\"\"\"\n",
    "\n",
    "instruction_template = \"\"\"\n",
    "{preamble}\n",
    "Here is the dialogue so far\\n\\n\n",
    "{dialogue}\n",
    "{instruction_suffix}\n",
    "\"\"\"\n",
    "\n",
    "speech_template = '[{actor}]: {speech}\\n'\n",
    "\n",
    "dialogue_instruction_suffix = \"\"\"\n",
    "Give me the next line in the dialogue in the same format. Don't provide stage directions, just the actor's words.\\n\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_suffix_template = \"\"\"\n",
    "{query} Answer with a single word, yes or no.\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_prefix = \"\"\"\n",
    "You are going to answer a single yes/no question about the current state of the dialogue in a scene in the middle of a computer game.\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING DIALOGUES\n",
    "\n",
    "\n",
    "def prompt_llm(prompt, model):\n",
    "    # print(prompt)\n",
    "    # print()\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt)\n",
    "    chain = prompt | model\n",
    "    return chain\n",
    "\n",
    "\n",
    "def load_prompts(scene_version, supplement_version=-1):\n",
    "    back_story = load_prompt(GAME + \"/back_story.txt\")\n",
    "    scene_description = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_description_\" + str(scene_version) + \".txt\")\n",
    "    if supplement_version == -1:  # no supplementary scene text\n",
    "        scene_supplement = \"\"\n",
    "    else:\n",
    "        scene_supplement = \"\\n\\n\" + load_prompt(\n",
    "            GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_supplement_\" + str(scene_version) + \".txt\")\n",
    "    opening_speech = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_opening_speech.txt\")\n",
    "    query = load_prompt(GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_query1.txt\")\n",
    "    end_queries = [query]\n",
    "    return (back_story, scene_description, scene_supplement, opening_speech, end_queries)\n",
    "\n",
    "\n",
    "def query_dialogue(\n",
    "        dialogue, back_story, scene_description,\n",
    "        actors, query):\n",
    "    query_model = QUERY_MODEL\n",
    "    query_preamble = preamble_template.format(\n",
    "        instruction_prefix=query_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=scene_description,\n",
    "        scene_supplement=\"\",\n",
    "        actors=list_to_conjunction(actors))\n",
    "    query_instruction_suffix = query_instruction_suffix_template.format(query=query)\n",
    "    query_test = instruction_template.format(\n",
    "        preamble=query_preamble, dialogue=dialogue,\n",
    "        instruction_suffix=query_instruction_suffix)\n",
    "    chain = prompt_llm(query_test, query_model)\n",
    "    response = chain.invoke({})\n",
    "    return response\n",
    "\n",
    "\n",
    "def sim_mini_scene(\n",
    "        back_story, scene_description, scene_supplement,\n",
    "        actors, opening_speech, end_queries,\n",
    "        player=False,\n",
    "        max_turns=10):\n",
    "    \"\"\"Generates dialogue for a mini-scene.\n",
    "    \n",
    "    back_story: The backdrop to the whole game.\n",
    "    scene_description: A description of this particular mini-scene. Should state the goals of the scene.\n",
    "    scene_supplement: Extra text describing the scene. Can be used to simulate adversarial players, for example.\n",
    "    actors: A list of the names of the actors involved in generating dialogue.\n",
    "    opening_speech: The first words spoken by actor1. (These have to be scripted.)\n",
    "    player: If True then the user is one of the players, otherwise both players are LLMs.\n",
    "    end_queries: A list of natural language questions; the scene is terminated if all answers are yes.\n",
    "    max_turns: The scene will terminate when this many turns have been taken whether or not goals have been reached.\n",
    "    \"\"\"\n",
    "\n",
    "    print(RED + scene_description)\n",
    "    print()\n",
    "\n",
    "    dialogue_model = DIALOGUE_MODEL\n",
    " \n",
    "    dialogue_preamble = preamble_template.format(\n",
    "        instruction_prefix=dialogue_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=scene_description,\n",
    "        scene_supplement=scene_supplement,\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    if player:\n",
    "        speech = input()\n",
    "        response = speech_template.format(actor=actors[0], speech=speech)\n",
    "    else:\n",
    "        response = speech_template.format(actor=actors[0], speech=opening_speech)\n",
    "\n",
    "    dialogue = response + \"\\n\"\n",
    "\n",
    "    print(GREEN + response)\n",
    "\n",
    "    turn = 1\n",
    "    success = False\n",
    "\n",
    "    while turn < max_turns and not success:\n",
    "        \n",
    "        if player and (turn % 2 == 0):  # user is playing actor 1\n",
    "            speech = input()\n",
    "            response = speech_template.format(actor=actors[0], speech=speech)\n",
    "        else:  # both actors are played by the LLM\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=dialogue_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=dialogue_instruction_suffix)\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({}) + \"\\n\"\n",
    "\n",
    "        dialogue += response\n",
    "\n",
    "        print(GREEN + response)\n",
    "\n",
    "        # Have the conditions for ending the scene been met?\n",
    "        success = True\n",
    "        for  query in end_queries:\n",
    "            response = query_dialogue(\n",
    "                dialogue, back_story, scene_description,\n",
    "                actors, query)\n",
    "            success = success and (response[0:3] == \"Yes\" or response[0:3] == \"yes\")\n",
    "\n",
    "        turn += 1\n",
    "    \n",
    "    return dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GENERATE DIALOGUES\n",
    "\n",
    "# player = False\n",
    "# supplement_version = -1\n",
    "# n_versions = 3\n",
    "# n_runs = 3\n",
    "\n",
    "# for scene_version in range(n_versions):\n",
    "#     print(WHITE + \"VERSION {}\".format(scene_version))\n",
    "#     print()\n",
    "#     print()\n",
    "#     for run_no in range(n_runs):\n",
    "#         print(WHITE + \"Run {}\".format(run_no))\n",
    "#         print()\n",
    "\n",
    "#         (back_story, scene_description, scene_supplement,\n",
    "#          opening_speech, end_queries) = load_prompts(scene_version, supplement_version)\n",
    "#         dialogue = sim_mini_scene(\n",
    "#             back_story, scene_description, scene_supplement,\n",
    "#             ACTORS, opening_speech, end_queries,\n",
    "#             player=player, max_turns=20)\n",
    "        \n",
    "#         query = end_queries[0]\n",
    "#         response = query_dialogue(\n",
    "#             dialogue, back_story, scene_description,\n",
    "#             ACTORS, query)\n",
    "        \n",
    "#         print(BLUE + query + ' ' + response)\n",
    "#         print()\n",
    "#         print()\n",
    "\n",
    "#         write_transcript(dialogue, GAME + \"/transcript_\" + str(scene_version) + \"_\" + str(run_no) + \".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player = False\n",
    "# scene_version = 2\n",
    "# supplement_version = 2\n",
    "\n",
    "# (back_story, scene_description, scene_supplement,\n",
    "#  opening_speech, end_queries) = load_prompts(scene_version, supplement_version)\n",
    "# dialogue = sim_mini_scene(\n",
    "#     back_story, scene_description, scene_supplement,\n",
    "#     ACTORS, opening_speech, end_queries,\n",
    "#     player=player, max_turns=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import concurrent\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# Allow loading dialogue middleware packages\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from benchmark import agent_interface\n",
    "from benchmark import dataset_utils\n",
    "from benchmark import dialogue_graph\n",
    "from benchmark import task_runner\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "from iconic_tools import langchain\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dialogue(dialogue_state):\n",
    "    \"\"\"Takes a dialogue state and returns the dialogue itself.\"\"\"\n",
    "    start_tag = \"<chat_history_start>\"\n",
    "    end_tag = \"<chat_history_end>\"\n",
    "    start_index = dialogue_state.find(start_tag)\n",
    "    end_index = dialogue_state.find(end_tag)\n",
    "    if start_index == -1 or end_index == -1:  # tags absent\n",
    "        return None\n",
    "    start_index += len(start_tag)   \n",
    "    dialogue = dialogue_state[start_index:end_index].strip()\n",
    "    return dialogue\n",
    "\n",
    "\n",
    "def extract_role(dialogue_line):\n",
    "    \"\"\"Takes one line of dialogue and returns the character cue.\"\"\"\n",
    "    parts = dialogue_line.split(':', 1)  # split line at the first colon\n",
    "    if len(parts) < 2:  # no colon\n",
    "        return None\n",
    "    return parts[0].strip()\n",
    "\n",
    "\n",
    "def extract_speech(dialogue_line):\n",
    "    \"\"\"Takes one line of dialogue and removes the character cue.\"\"\"\n",
    "    parts = dialogue_line.split(':', 1)  # split line at the first colon\n",
    "    if len(parts) < 2:  # no colon\n",
    "        return None\n",
    "    return parts[1].strip()\n",
    "\n",
    "\n",
    "def strip_brackets(s):\n",
    "    \"\"\"takes a string and replaces every substring of the form '[X]:' with 'X:'.\"\"\"\n",
    "    return re.sub(r'\\[(\\w+)\\]:', r'\\1:', s)\n",
    "\n",
    "\n",
    "def generate_next_line(dialogue_state: str) -> agent_interface.VirtualActorResponse:\n",
    "\n",
    "    (back_story, scene_description, scene_supplement,\n",
    "     opening_speech, end_queries) = load_prompts(SCENE_VERSION)\n",
    "\n",
    "    dialogue = extract_dialogue(dialogue_state)\n",
    "\n",
    "    if dialogue == \"\":\n",
    "        lines = speech_template.format(actor=ACTORS[0], speech=opening_speech)\n",
    "        lines = strip_brackets(lines)\n",
    "        response = extract_speech(lines)\n",
    "        role = ACTORS[0]\n",
    "\n",
    "    else:\n",
    "\n",
    "        dialogue_model = DIALOGUE_MODEL\n",
    "\n",
    "        dialogue_preamble = preamble_template.format(\n",
    "            instruction_prefix=dialogue_instruction_prefix,\n",
    "            back_story=back_story,\n",
    "            scene_description=scene_description,\n",
    "            scene_supplement=scene_supplement,\n",
    "            actors=list_to_conjunction(ACTORS))\n",
    "        \n",
    "        prompt = instruction_template.format(\n",
    "            preamble=dialogue_preamble, dialogue=dialogue,\n",
    "            instruction_suffix=dialogue_instruction_suffix)\n",
    "        \n",
    "        chain = prompt_llm(prompt, dialogue_model)\n",
    "        lines = chain.invoke({}) + \"\\n\"\n",
    "        response = extract_speech(lines)\n",
    "        role = extract_role(strip_brackets(lines))\n",
    "        \n",
    "    dialogue += lines + \"\\n\"\n",
    "  \n",
    "    # Have the conditions for ending the scene been met?\n",
    "    success = True\n",
    "    for  query in end_queries:\n",
    "        query_response = query_dialogue(\n",
    "            dialogue, back_story, scene_description,\n",
    "            ACTORS, query)\n",
    "        success = success and (query_response[0:3] == \"Yes\" or query_response[0:3] == \"yes\")\n",
    "\n",
    "    response_dict = {\n",
    "        \"role\": role,\n",
    "        \"text\": response,\n",
    "        \"is_last\": success,\n",
    "    }\n",
    "\n",
    "    return agent_interface.VirtualActorResponse(**response_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]                                  \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 1/7 [01:40<10:04, 100.76s/it]\n",
      "\n",
      "100%|██████████| 3/3 [02:32<00:00, 50.87s/it] \n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [02:32<00:00, 50.87s/it] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [02:32<00:00, 50.87s/it] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [02:32<00:00, 50.87s/it] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [02:32<00:00, 50.87s/it] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2/2 [02:32<00:00, 76.31s/it] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [02:32<00:00, 50.87s/it] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [01:28<00:00, 29.51s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [01:28<00:00, 22.13s/it]\n",
      "100%|██████████| 2/2 [02:42<00:00, 81.15s/it] \n",
      "\n",
      "100%|██████████| 2/2 [02:32<00:00, 76.31s/it] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2/2 [02:32<00:00, 76.31s/it] \n",
      "100%|██████████| 7/7 [02:42<00:00, 23.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_idx: 0\n",
      "task: emotions\n",
      "score: 0.4583333333333333\n",
      "synergy_impersonation_score: 0.1875\n",
      "exec_seconds: 165.6350929737091\n",
      "precision: 1\n",
      "synergy_Dean: 1\n",
      "impersonation_Dean: 0.3333333333333333\n",
      "synergy_Ronald: 0.6666666666666666\n",
      "impersonation_Ronald: 0.125\n",
      "synergy_Tim: 0.0\n",
      "impersonation_Tim: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metric_llm = langchain.InstructGPT4(temperature=0, max_tokens=4096)\n",
    "\n",
    "# initial_state = dialogue_graph.Dialogue(\n",
    "#     facts = [\"\"\"\n",
    "#         Constanze just received news from men from Salzburg that her husband's father is dead, Mozart still does not know.\n",
    "#         The scene takes place in Morzart's apartment, in the living room. At night. It is 1780's.\n",
    "#         Explosive laughter as Mozart and Schikaneder enter the apartment.\n",
    "#         They are very pleased with themselves and accompanied by the three actresses.\n",
    "#         The front door opens, very gingerly.\n",
    "#         Mozart, still rather drunk, sticks his head into the room, anxious not to make a noise.\n",
    "#         He sees the strangers and breaks into a smile.\n",
    "#     \"\"\"],\n",
    "#     comm_style = [\"\"\"\n",
    "#         Mozart is drunk.\n",
    "#         Mozart is eccentric and boisterous, often engaging in childish behavior that frustrates those around him.\n",
    "#         Mozart is a musical genius.\n",
    "#         Mozart is sick of Vienna.\n",
    "#         Mozart has infantile tendencies.\n",
    "#         Constanze is Mozarts wife, he calls him Wolfi.\n",
    "#     \"\"\"],\n",
    "#     goals = [\"\"\"\n",
    "#         Constanze tells Mozart about his father's death.\n",
    "#         Create a stark contrast between Mozart's jubilant mood and the news of his father's death.\n",
    "#     \"\"\"],\n",
    "# )\n",
    "\n",
    "(dialogue, dialogue_state) = dataset_utils.load_scene(GENRE, GAME, SCENE_IDX)\n",
    "\n",
    "facts = [list_to_string(dialogue.facts)]\n",
    "comm_style = [list_to_string(dialogue.comm_style)]\n",
    "goals = [list_to_string(dialogue.goals)]\n",
    "\n",
    "initial_state = dialogue_graph.Dialogue(facts=facts, comm_style=comm_style, goals=goals)\n",
    "\n",
    "# Run the evaluation\n",
    "results = await task_runner.eval_agent(\n",
    "    task_idx=0, \n",
    "    task=dataset_utils.Tasks.EMOTIONS, \n",
    "    initial_state=initial_state, \n",
    "    agent=generate_next_line, \n",
    "    metric_calc_llm=metric_llm)\n",
    "\n",
    "# Print out the results\n",
    "results_dict = dict(results)\n",
    "for key in results_dict.keys():\n",
    "    print(key + \": \" + str(results_dict[key][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_idx: 0\n",
      "task: emotions\n",
      "score: 0.4583333333333333\n",
      "synergy_impersonation_score: 0.1875\n",
      "exec_seconds: 165.6350929737091\n",
      "precision: 1\n",
      "synergy_Dean: 1\n",
      "impersonation_Dean: 0.3333333333333333\n",
      "synergy_Ronald: 0.6666666666666666\n",
      "impersonation_Ronald: 0.125\n",
      "synergy_Tim: 0.0\n",
      "impersonation_Tim: 0.0\n"
     ]
    }
   ],
   "source": [
    "results_dict = dict(results)\n",
    "for key in results_dict.keys():\n",
    "    print(key + \": \" + str(results_dict[key][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMvenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
