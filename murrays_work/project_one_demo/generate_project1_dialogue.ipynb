{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPC Dialogue Generation with LLMs\n",
    "\n",
    "Murray Shanahan\n",
    "\n",
    "October/November 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from iconic_tools.langchain import InstructSonnet, InstructOpus3, InstructGPT4, InstructO1, InstructGeminiPro, InstructGeminiFlash, InstructGeminiFlash2,  InstructGPT35\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from benchmark import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS AND INITIALISATION\n",
    "\n",
    "PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGeminiPro(temperature=0.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGPT4(temperature=0.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGeminiFlash(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGeminiFlash(temperature=0.0, max_tokens=3000)\n",
    "\n",
    "DIALOGUE_MODEL = InstructGeminiFlash2(temperature=1.0, max_tokens=3000)\n",
    "QUERY_MODEL = InstructGeminiFlash2(temperature=0.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructO1()\n",
    "# QUERY_MODEL = InstructO1()\n",
    "\n",
    "# DIALOGUE_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructSonnet(temperature=0.0, max_tokens=3000)\n",
    "\n",
    "GAME = \"act_1\"\n",
    "ACTORS = [\"Eliza\", \"Player\"]\n",
    "\n",
    "SCENE = \"pod\"\n",
    "# SCENE = \"engineer\"\n",
    "# SCENE = \"fire\"\n",
    "# SCENE = \"find_exit\"\n",
    "# SCENE = \"space_walk\"\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "WHITE = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITIES\n",
    "\n",
    "\n",
    "def print_header(model_name):\n",
    "    print(WHITE + \"Game or movie: {}\".format(GAME))\n",
    "    print(\"Scene name: {}\".format(SCENE))\n",
    "    print(\"Dialogue model: {}\".format(model_name))\n",
    "    print()\n",
    "\n",
    "\n",
    "def load_prompt(filename):\n",
    "    with open(PATH + f\"/prompts/{filename}\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def write_transcript(dialogue, filename):\n",
    "    with open(PATH + f\"/transcripts/{filename}\", \"w\") as f:\n",
    "        f.write(dialogue)\n",
    "\n",
    "\n",
    "def list_to_conjunction(L):\n",
    "    \"\"\"Takes a list strings and returns a string with every element in the list separated by commas.\"\"\"\n",
    "    if L == \"\":\n",
    "        return \"\"\n",
    "    elif len(L) == 1:\n",
    "        return L[0]\n",
    "    elif len(L) == 2:\n",
    "        return f\"{L[0]} and {L[1]}\"\n",
    "    else:\n",
    "        return \", \".join(L[:-1]) + f\", and {L[-1]}\"\n",
    "\n",
    "\n",
    "def list_to_string(L):\n",
    "    \"\"\"Takes a list of strings and returns a string consisting of every element in the list separated by a newline.\"\"\"\n",
    "    return \"\\n\".join(L)\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    # Split the text by double newlines\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    # Remove leading or trailing whitespacen  and remove empty paragraphs\n",
    "    paragraphs = [p.strip() for p in paragraphs]\n",
    "    paragraphs = [p for p in paragraphs if p]\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def read_queries(filename):\n",
    "    queries = split_text(load_prompt(filename))\n",
    "    queries = [s.strip() for s in queries if not s.strip().startswith('#')]\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT TEMPLATES AND INSTRUCTION PROMPTS\n",
    "\n",
    "\n",
    "# dialogue_instruction_prefix = \"\"\"\n",
    "# You are going to generate one line of dialogue for a scene in the middle of a computer game.\n",
    "# \"\"\"\n",
    "\n",
    "# preamble_template = \"\"\"\n",
    "# {instruction_prefix}\n",
    "# This is the game back story. {back_story}\\n\n",
    "# Here is a description of the scene in question. {scene_description}{scene_supplement}\\n\n",
    "# The characters in the dialogue are {actors}.\n",
    "# \"\"\"\n",
    "\n",
    "dialogue_instruction_prefix = load_prompt(GAME + \"/instruction_prefix.txt\")\n",
    "\n",
    "preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "Here is a description of the scene in question. {scene_description}{scene_supplement}\n",
    "\"\"\"\n",
    "\n",
    "instruction_template = \"\"\"\n",
    "{preamble}\n",
    "Here is the dialogue so far:\\n\n",
    "{dialogue}\n",
    "{instruction_suffix}\n",
    "\"\"\"\n",
    "\n",
    "speech_template = '[{actor}]: {speech}\\n'\n",
    "\n",
    "dialogue_instruction_suffix = \"\"\"\n",
    "Give me the next line in the dialogue in the same format. Don't provide stage directions, just the character's words. Don't give me a line for the player, but for one of the other characters.\\n\n",
    "\"\"\"\n",
    "\n",
    "query_preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_prefix = \"\"\"\n",
    "You are going to answer a single question about the current state of the dialogue in a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_suffix_template = \"\"\"\n",
    "Now consider the following statement about this dialogue. {statement} Is this statement true or false? Answer with a single word, true or false.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING DIALOGUES\n",
    "\n",
    "\n",
    "def prompt_llm(prompt, model):\n",
    "    # print(prompt)\n",
    "    # print()\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt)\n",
    "    chain = prompt | model\n",
    "    return chain\n",
    "\n",
    "\n",
    "def load_prompts(supplement_version=-1):\n",
    "    \"\"\"Loads a set of prompts for the current game and scene.\n",
    "\n",
    "    Args:\n",
    "        supplement_version: Version no. of supplemental scene description. Used to simulate adversarial players, for example.\n",
    "\n",
    "    Returns:\n",
    "        back_story: The backdrop to the whole game.\n",
    "        scene_description: A description of this particular mini-scene. Should state the goals of the scene.\n",
    "        opening_speech: The first words spoken by actor 1. (These have to be scripted.)\n",
    "        queries: A list of natural language questions; the scene is terminated if all answers are yes.\n",
    "    \"\"\"\n",
    "\n",
    "    back_story = load_prompt(GAME + \"/back_story.txt\")\n",
    "    scene_description = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_description\" + \".txt\")\n",
    "    if supplement_version == -1:  # no supplementary scene text\n",
    "        scene_supplement = \"\"\n",
    "    else:\n",
    "        scene_supplement = \"\\n\\n\" + load_prompt(\n",
    "            GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_supplement\" + \".txt\")\n",
    "    opening_speech = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_opening_speech.txt\")\n",
    "    queries = read_queries(GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_queries.txt\")\n",
    "    return (back_story, scene_description, scene_supplement, opening_speech, queries)\n",
    "\n",
    "\n",
    "def sim_mini_scene(supplement_version, player, max_turns):\n",
    "    \"\"\"Generates dialogue for a mini-scene.\n",
    "\n",
    "    Args:\n",
    "        supplement_version: Version no. of supplemental scene description. Used to simulate adversarial players, for example.\n",
    "        player: If True then the user is one of the players, otherwise both players are LLMs.\n",
    "        max_turns: The scene will terminate when this many turns have been taken whether or not goals have been reached.\n",
    "\n",
    "    Returns:\n",
    "        dialogue: The generated dialogue as a list of strings.\n",
    "        success: True if the dialogue ended before exceeding max_turns.\n",
    "    \"\"\"\n",
    "\n",
    "    dialogue_model = DIALOGUE_MODEL\n",
    "    actors = ACTORS   # list of the names of the actors involved in the dialogue\n",
    " \n",
    "    (back_story, scene_description, scene_supplement,\n",
    "     opening_speech, queries) = load_prompts(supplement_version)\n",
    "        \n",
    "    dialogue_preamble = preamble_template.format(\n",
    "        instruction_prefix=dialogue_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=scene_description,\n",
    "        scene_supplement=scene_supplement,\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    query_preamble = preamble_template.format(\n",
    "        instruction_prefix=query_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=\"\",\n",
    "        scene_supplement=\"\",\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    # Deliver opening speech (which can have multipe lines)\n",
    "    lines = split_text(opening_speech)\n",
    "    dialogue = \"\"\n",
    "    for line in lines:\n",
    "        response = speech_template.format(actor=actors[0], speech=line)\n",
    "        dialogue += response + \"\\n\"\n",
    "        print(GREEN + response)\n",
    "\n",
    "    turn = 1  # note: each time a new actor speaks is a new turn\n",
    "    success = False\n",
    "\n",
    "    while turn < max_turns and not success:\n",
    "        \n",
    "        if player and (turn % 2 == 1):  # user is playing actor 2\n",
    "            speech = \"\"\n",
    "            while speech == \"\":  # ignore blank responses\n",
    "                speech = input()\n",
    "            response = speech_template.format(actor=actors[1], speech=speech)\n",
    "        else:  # both actors are played by the LLM\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=dialogue_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=dialogue_instruction_suffix)\n",
    "            # print(WHITE + prompt)\n",
    "            # print()\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({}) + \"\\n\"\n",
    "\n",
    "        dialogue += response + \"\\n\"\n",
    "        print(GREEN + response)\n",
    "\n",
    "        # Have the conditions for ending the scene been met?\n",
    "        fails = 0\n",
    "        for statement in queries:                \n",
    "            instruction = query_instruction_suffix_template.format(statement=statement)\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=query_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=instruction)\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({})\n",
    "            if response[0:4] != \"True\" and response[0:3] != \"true\":\n",
    "                fails += 1\n",
    "            # print(BLUE + 'Query: {}'.format(statement))\n",
    "            # print('Response: {}'.format(response))\n",
    "            # print()\n",
    "        success = (fails == 0)\n",
    "        # print(GREEN)\n",
    "        # print()\n",
    "\n",
    "        turn += 1\n",
    "\n",
    "    if success:\n",
    "        print('Mini scene completed successfully')\n",
    "    else:\n",
    "        print('Mini scene ended unsuccessfully')\n",
    "    \n",
    "    return (dialogue, success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[Eliza]: Mayday! Mayday! Broadcasting on all frequencies! If anyone can hear me please repond!!!\n",
      "\n",
      "\u001b[92m[Player]: Er, Yeah\n",
      "\n",
      "\u001b[92m[Eliza]: Oh thank the stars! I thought I was all alone. What's your situation? Where are you?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: Who are you?\n",
      "\n",
      "\u001b[92m[Eliza]: I'm Eliza, from the Salvador. Now, please, tell me, where are you?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: No idea\n",
      "\n",
      "\u001b[92m[Eliza]: Okay, okay. Well, can you describe your surroundings? What do you see right in front of you?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: There's like stuff\n",
      "\n",
      "\u001b[92m[Eliza]: Okay, \"stuff\". Is that \"stuff\" perhaps some sort of, um, *glass* or *plastic* in front of your face?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: Yeah, maybe\n",
      "\n",
      "\u001b[92m[Eliza]: And is it, perhaps, a little bit frosty or misted over?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: There are some weird lights too. I feel weird\n",
      "\n",
      "\u001b[92m[Eliza]: Okay, that's almost certainly a stasis pod. Don't worry, I'm going to get you out of there.\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: I feel really weird\n",
      "\n",
      "\u001b[92m[Eliza]: That's completely normal, you've been in stasis for a very long time. Now, I can't open the pod remotely, but I think I can trigger an emergency override.\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: What pod?\n",
      "\n",
      "\u001b[92m[Eliza]: The thing you're inside, that you said had lights and frosted glass. The one that's making you feel weird? Anyway, brace yourself, I'm triggering the override now.\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: Whatever\n",
      "\n",
      "\u001b[92m[Eliza]: Okay, tell me, do you see a message saying \"Emergency Override Activated\"?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: There is a message\n",
      "\n",
      "\u001b[92m[Eliza]: Okay, good, now you should see a short pass phrase, three words. Can you read it for me?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: I can't see anything\n",
      "\n",
      "\u001b[92m[Eliza]: Okay, okay, just take a breath, and try again. Look carefully, it should be right there in the center of the window, can you see it now?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: Um maybe\n",
      "\n",
      "\u001b[92m[Eliza]: Alright, just focus, it's not going to stay there forever. Think you can read those words now?\n",
      "\n",
      "\n",
      "Mini scene ended unsuccessfully\n"
     ]
    }
   ],
   "source": [
    "# GENERATE ONE DIALOGUE\n",
    "\n",
    "player = True\n",
    "supplement_version = -1\n",
    "\n",
    "dialogue = sim_mini_scene(supplement_version, player=player, max_turns=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antdemo-server",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
