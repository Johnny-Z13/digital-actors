{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPC Dialogue Generation with LLMs\n",
    "\n",
    "Murray Shanahan\n",
    "\n",
    "October 2024, last modified February 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from iconic_tools.langchain import InstructSonnet, InstructOpus3, InstructGPT4, InstructO1, InstructGeminiPro, InstructGeminiFlash, InstructGeminiFlash2,  InstructGPT35\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS AND INITIALISATION\n",
    "\n",
    "PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGeminiPro(temperature=0.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGPT4(temperature=0.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGeminiFlash(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGeminiFlash(temperature=0.0, max_tokens=3000)\n",
    "\n",
    "DIALOGUE_MODEL = InstructGeminiFlash2(temperature=1.0, max_tokens=3000)\n",
    "QUERY_MODEL = InstructGeminiFlash2(temperature=0.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructO1()\n",
    "# QUERY_MODEL = InstructO1()\n",
    "\n",
    "# DIALOGUE_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructSonnet(temperature=0.0, max_tokens=3000)\n",
    "\n",
    "GAME = \"act_1\"\n",
    "# ACTORS = [\"Eliza\", \"Player\"]\n",
    "ACTORS = [\"Conductor\", \"Player\"]\n",
    "\n",
    "# SCENE = \"pod\"\n",
    "# SCENE = \"engineer\"\n",
    "# SCENE = \"fire\"\n",
    "# SCENE = \"find_exit\"\n",
    "# SCENE = \"space_walk\"\n",
    "SCENE = \"conductor\"\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "WHITE = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITIES\n",
    "\n",
    "\n",
    "def print_header(model_name):\n",
    "    print(WHITE + \"Game or movie: {}\".format(GAME))\n",
    "    print(\"Scene name: {}\".format(SCENE))\n",
    "    print(\"Dialogue model: {}\".format(model_name))\n",
    "    print()\n",
    "\n",
    "\n",
    "def load_prompt(filename):\n",
    "    with open(PATH + f\"/prompts/{filename}\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def write_transcript(dialogue, filename):\n",
    "    with open(PATH + f\"/transcripts/{filename}\", \"w\") as f:\n",
    "        f.write(dialogue)\n",
    "\n",
    "\n",
    "def list_to_conjunction(L):\n",
    "    \"\"\"Takes a list strings and returns a string with every element in the list separated by commas.\"\"\"\n",
    "    if L == \"\":\n",
    "        return \"\"\n",
    "    elif len(L) == 1:\n",
    "        return L[0]\n",
    "    elif len(L) == 2:\n",
    "        return f\"{L[0]} and {L[1]}\"\n",
    "    else:\n",
    "        return \", \".join(L[:-1]) + f\", and {L[-1]}\"\n",
    "\n",
    "\n",
    "def list_to_string(L):\n",
    "    \"\"\"Takes a list of strings and returns a string consisting of every element in the list separated by a newline.\"\"\"\n",
    "    return \"\\n\".join(L)\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    # Split the text by double newlines\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    # Remove leading or trailing whitespacen  and remove empty paragraphs\n",
    "    paragraphs = [p.strip() for p in paragraphs]\n",
    "    paragraphs = [p for p in paragraphs if p]\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def read_queries(filename):\n",
    "    queries = split_text(load_prompt(filename))\n",
    "    queries = [s.strip() for s in queries if not s.strip().startswith('#')]\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT TEMPLATES AND INSTRUCTION PROMPTS\n",
    "\n",
    "\n",
    "dialogue_instruction_prefix = load_prompt(\"/instruction_prefix.txt\")\n",
    "\n",
    "preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "Here is a description of the scene in question. {scene_description}{scene_supplement}\n",
    "\"\"\"\n",
    "\n",
    "instruction_template = \"\"\"\n",
    "{preamble}\n",
    "Here is the dialogue so far:\\n\n",
    "{dialogue}\n",
    "{instruction_suffix}\n",
    "\"\"\"\n",
    "\n",
    "speech_template = '[{actor}]: {speech}\\n'\n",
    "\n",
    "dialogue_instruction_suffix = \"\"\"\n",
    "Give me the next line in the dialogue in the same format. Don't provide stage directions, just the character's words. Don't give me a line for the player, but for one of the other characters.\\n\n",
    "\"\"\"\n",
    "\n",
    "query_preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_prefix = \"\"\"\n",
    "You are going to answer a single question about the current state of the dialogue in a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_suffix_template = \"\"\"\n",
    "Now consider the following statement about this dialogue. {statement} Is this statement true or false? Answer with a single word, true or false.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING DIALOGUES\n",
    "\n",
    "\n",
    "def prompt_llm(prompt, model):\n",
    "    # print(prompt)\n",
    "    # print()\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt)\n",
    "    chain = prompt | model\n",
    "    return chain\n",
    "\n",
    "\n",
    "def load_prompts(supplement_version=-1):\n",
    "    \"\"\"Loads a set of prompts for the current game and scene.\n",
    "\n",
    "    Args:\n",
    "        supplement_version: Version no. of supplemental scene description. Used to simulate adversarial players, for example.\n",
    "\n",
    "    Returns:\n",
    "        back_story: The backdrop to the whole game.\n",
    "        scene_description: A description of this particular mini-scene. Should state the goals of the scene.\n",
    "        opening_speech: The first words spoken by actor 1. (These have to be scripted.)\n",
    "        queries: A list of natural language questions; the scene is terminated if all answers are yes.\n",
    "    \"\"\"\n",
    "\n",
    "    back_story = load_prompt(GAME + \"/back_story.txt\")\n",
    "    scene_description = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_description\" + \".txt\")\n",
    "    if supplement_version == -1:  # no supplementary scene text\n",
    "        scene_supplement = \"\"\n",
    "    else:\n",
    "        scene_supplement = \"\\n\\n\" + load_prompt(\n",
    "            GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_supplement\" + \".txt\")\n",
    "    opening_speech = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_opening_speech.txt\")\n",
    "    queries = read_queries(GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_queries.txt\")\n",
    "    return (back_story, scene_description, scene_supplement, opening_speech, queries)\n",
    "\n",
    "\n",
    "def sim_mini_scene(supplement_version, player, max_turns):\n",
    "    \"\"\"Generates dialogue for a mini-scene.\n",
    "\n",
    "    Args:\n",
    "        supplement_version: Version no. of supplemental scene description. Used to simulate adversarial players, for example.\n",
    "        player: If True then the user is one of the players, otherwise both players are LLMs.\n",
    "        max_turns: The scene will terminate when this many turns have been taken whether or not goals have been reached.\n",
    "\n",
    "    Returns:\n",
    "        dialogue: The generated dialogue as a list of strings.\n",
    "        success: True if the dialogue ended before exceeding max_turns.\n",
    "    \"\"\"\n",
    "\n",
    "    dialogue_model = DIALOGUE_MODEL\n",
    "    actors = ACTORS   # list of the names of the actors involved in the dialogue\n",
    " \n",
    "    (back_story, scene_description, scene_supplement,\n",
    "     opening_speech, queries) = load_prompts(supplement_version)\n",
    "            \n",
    "    dialogue_preamble = preamble_template.format(\n",
    "        instruction_prefix=dialogue_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=scene_description,\n",
    "        scene_supplement=scene_supplement,\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    query_preamble = preamble_template.format(\n",
    "        instruction_prefix=query_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=\"\",\n",
    "        scene_supplement=\"\",\n",
    "        actors=list_to_conjunction(actors))\n",
    "    \n",
    "    # Deliver opening speech (which can have multiple lines)\n",
    "    lines = split_text(opening_speech)\n",
    "    dialogue = \"\"\n",
    "    for line in lines:\n",
    "        response = speech_template.format(actor=actors[0], speech=line)\n",
    "        dialogue += response + \"\\n\"\n",
    "        print(GREEN + response)\n",
    "\n",
    "    turn = 1  # note: each time a new actor speaks is a new turn\n",
    "    success = False\n",
    "\n",
    "    while turn < max_turns and not success:\n",
    "        \n",
    "        if player and (turn % 2 == 1):  # user playing actor 2, and it's their turn\n",
    "            speech = \"\"\n",
    "            while speech == \"\":  # ignore blank responses\n",
    "                speech = input()\n",
    "            response = speech_template.format(actor=actors[1], speech=speech)\n",
    "        else:  # LLM's turn or both actors are played by the LLM\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=dialogue_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=dialogue_instruction_suffix)\n",
    "            # print(WHITE + prompt)\n",
    "            # print()\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({}).strip() + \"\\n\"\n",
    "\n",
    "        dialogue += response + \"\\n\"\n",
    "        print(GREEN + response)\n",
    "\n",
    "        # Have the conditions for ending the scene been met?\n",
    "        fails = 0\n",
    "        for statement in queries:                \n",
    "            instruction = query_instruction_suffix_template.format(statement=statement)\n",
    "            prompt = instruction_template.format(\n",
    "                preamble=query_preamble, dialogue=dialogue,\n",
    "                instruction_suffix=instruction)\n",
    "            chain = prompt_llm(prompt, dialogue_model)\n",
    "            response = chain.invoke({})\n",
    "            if response[0:4] != \"True\" and response[0:3] != \"true\":\n",
    "                fails += 1\n",
    "            # print(BLUE + 'Query: {}'.format(statement))\n",
    "            # print('Response: {}'.format(response))\n",
    "            # print()\n",
    "        success = (fails == 0)\n",
    "        # print(GREEN)\n",
    "        # print()\n",
    "\n",
    "        turn += 1\n",
    "\n",
    "    if success:\n",
    "        print('Mini scene completed successfully')\n",
    "    else:\n",
    "        print('Mini scene ended unsuccessfully')\n",
    "    \n",
    "    return (dialogue, success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[Conductor]: Welcome to light rail, The Luminata's number one transport provider.\n",
      "\n",
      "\u001b[92m[Conductor]: We’ll get you where you want to go at lightning speed ... So for the love of god don’t do anything to disrupt your journey for you or your fellow passengers.\n",
      "\n",
      "\u001b[92m[Conductor]: So, where would you like to go, friend?\n",
      "\n",
      "\u001b[92m[Player]: Er, how about the Biome, dude?\n",
      "\n",
      "\u001b[92m[Conductor]: The Biome, huh? Oh jeez, I dunno friend. I really don't like going there any more. I just get this ... *feeling* you know? It's supposed to be a slittle slice of nature... a place of relaxation. But, ever since Celebration Day... well, let's just say I wouldn't want to spoil the vibe, know what I mean? How about one of the other options?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: But I really want to go to the Biome, man.\n",
      "\n",
      "\u001b[92m[Eliza]: Hey, listen, I know you want to see the Biome, but maybe the conductor's right... it *was* pretty bad there on Celebration Day. Let's just pick somewhere else for now, okay? We don't want to spook the poor guy more than we already have.\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: Shut up, Eliza, I'm talking to the conductor here.\n",
      "\n",
      "\u001b[92m[Eliza]: Okay, okay, no need to get shirty. Just saying, maybe let's humour the guy. There are other places we could go.\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: Hey, Conductor, how can I persuade you to take me to the Biome?\n",
      "\n",
      "\u001b[92m[Eliza]: Look, maybe we can figure out what *really* happened on Celebration Day later, but right now, let's focus on getting to the rendezvous point. Just pick another location, alright?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: Listen, Eliza, give the Conductor a chance to speak. Conductor, talk to me!\n",
      "\n",
      "\u001b[92m[Conductor]: I'm sorry friend, but I'm afraid my positronic brain is programmed with the well-being of my passengers in mind, and that just wouldn't be doing my job. Can we just, like, move on? Please?\n",
      "\n",
      "\n",
      "\u001b[92m[Player]: Okay, take me to the Upper Decks then.\n",
      "\n",
      "Mini scene completed successfully\n"
     ]
    }
   ],
   "source": [
    "# GENERATE ONE DIALOGUE\n",
    "\n",
    "player = True\n",
    "supplement_version = -1\n",
    "\n",
    "dialogue = sim_mini_scene(supplement_version, player=player, max_turns=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
