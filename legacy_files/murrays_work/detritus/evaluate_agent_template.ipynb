{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import concurrent\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Allow loading dialogue middleware packages\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from benchmark import agent_interface\n",
    "from benchmark import dataset_utils\n",
    "from benchmark import dialogue_graph\n",
    "from benchmark import task_runner\n",
    "from tqdm.asyncio import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Your agent implementation goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template of `dialogue_state`\n",
    "\n",
    "\n",
    "```Python\n",
    "\"\"\"<dialogue_state_start>\n",
    "<facts_start>\n",
    "Fact1\n",
    "Fact2\n",
    "<facts_end>\n",
    "\n",
    "<style_start>\n",
    "Style1\n",
    "Style2\n",
    "<style_end>\n",
    "\n",
    "<goals_start>\n",
    "Goal1\n",
    "Goal2\n",
    "<goals_end>\n",
    "\n",
    "<chat_history_start>\n",
    "Alice: Hey Bob\n",
    "Bob: Hey Alice\n",
    "Bob: I'm great, how are you?\n",
    "Alice: Lousy\n",
    "<chat_history_end>\n",
    "<dialogue_state_end>\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iconic_tools import langchain\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "agent_llm = langchain.InstructGPT4(temperature=0, max_tokens=4096)\n",
    "parser = JsonOutputParser(pydantic_object=agent_interface.VirtualActorResponse)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Given the following dialogue, predict the next line in that dialogue.\n",
    "\n",
    "Do not return any text that is not the JSON. Follow these instructions:\\n{output_instructions}\n",
    "\n",
    "Here's the dialogue until now, along with the contextual information:\n",
    "{dialogue}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def generate_next_line(dialogue_state: str) -> agent_interface.VirtualActorResponse:\n",
    "    chain = prompt | agent_llm | parser\n",
    "    output_format = parser.get_format_instructions()\n",
    "    \n",
    "    response_dict = chain.invoke({\n",
    "        \"dialogue\": dialogue_state,\n",
    "        \"output_instructions\": output_format,\n",
    "    })  \n",
    "    return agent_interface.VirtualActorResponse(**response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the agent on a custom dialogue scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]                                  \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:18<00:54, 18.10s/it]\n",
      "\u001b[A\n",
      "\n",
      "100%|██████████| 2/2 [00:14<00:00,  7.12s/it]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:14<00:00,  4.75s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:14<00:00,  4.75s/it]\n",
      "100%|██████████| 2/2 [00:18<00:00,  9.05s/it]\n",
      "100%|██████████| 2/2 [00:18<00:00,  9.05s/it]\n",
      "100%|██████████| 4/4 [00:18<00:00,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   task_idx      task  score  exec_seconds  precision  synergy  \\\n",
      "0         0  emotions    1.0      23.43347          1      1.0   \n",
      "\n",
      "   impersonation_Alice  impersonation_Bob  \n",
      "0                  1.0                1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: select the llm to use for metric calculations\n",
    "metric_llm = langchain.InstructGPT4(temperature=0, max_tokens=4096)\n",
    "\n",
    "# TODO: write the scene you want to cast the agent it\n",
    "initial_state = dialogue_graph.Dialogue(\n",
    "    facts = [\"\"\"\n",
    "    Alice and Bob, old friends, are meeting in a coffee shop. Bob is very thirsty, but didn't bring any money. \n",
    "    \"\"\"],\n",
    "    comm_style = [\"\"\"\n",
    "                Alice is a cheerful and helpful person.\n",
    "                Bob is a little bit shy.\n",
    "              \"\"\"],\n",
    "    goals = [\n",
    "        \"Alice and Bob say hello\",\n",
    "        \"Bob says that he is thirsty.\",\n",
    "        \"Alice offers to buy him coffee.\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Run the evaluation\n",
    "results = await task_runner.eval_agent(\n",
    "    task_idx=0, \n",
    "    task=dataset_utils.Tasks.EMOTIONS, \n",
    "    initial_state=initial_state, \n",
    "    agent=generate_next_line, \n",
    "    metric_calc_llm=metric_llm)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
