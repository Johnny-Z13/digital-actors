{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from iconic_tools.langchain import InstructSonnet, InstructOpus3, InstructGPT4, InstructGeminiPro, InstructGPT35\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS AND INITIALISATION\n",
    "\n",
    "PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "# DIALOGUE_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructGeminiPro(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "DIALOGUE_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "QUERY_MODEL = InstructGPT4(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# DIALOGUE_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "# QUERY_MODEL = InstructSonnet(temperature=1.0, max_tokens=3000)\n",
    "\n",
    "# GAME = \"troy\"\n",
    "# SCENE = \"achilles\"\n",
    "# ACTORS = [\"Achilles\", \"Odysseus\"]\n",
    "\n",
    "# GENRE = \"drama\"\n",
    "# SCENE_IDX = 124\n",
    "# GAME = \"amadeus\"\n",
    "# SCENE = \"constanze\"\n",
    "# ACTORS = [\"Mozart\", \"Constanze\", \"Schikaneder\"]\n",
    "# SCENE_VERSION = 2\n",
    "\n",
    "# GENRE = \"comedy\"\n",
    "# SCENE_IDX = 116\n",
    "# GAME = \"cedar_rapids\"\n",
    "# SCENE = \"car\"\n",
    "# ACTORS = [\"Tim\", \"Ronald\", \"Dean\", \"Joan\"]\n",
    "# SCENE_VERSION = 0\n",
    "\n",
    "GENRE = \"drama\"\n",
    "SCENE_IDX = 2\n",
    "GAME = \"bound\"\n",
    "SCENE = \"coffee\"\n",
    "ACTORS = [\"Violet\", \"Corky\"]\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "WHITE = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITIES\n",
    "\n",
    "\n",
    "def load_prompt(filename):\n",
    "    with open(PATH + f\"/prompts/{filename}\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def write_transcript(dialogue, filename):\n",
    "    with open(PATH + f\"/transcripts/{filename}\", \"w\") as f:\n",
    "        f.write(dialogue)\n",
    "\n",
    "\n",
    "def list_to_conjunction(L):\n",
    "    \"\"\"Takes a list strings and returns a string with every element in the list separated by commas.\"\"\"\n",
    "    if L == \"\":\n",
    "        return \"\"\n",
    "    elif len(L) == 1:\n",
    "        return L[0]\n",
    "    elif len(L) == 2:\n",
    "        return f\"{L[0]} and {L[1]}\"\n",
    "    else:\n",
    "        return \", \".join(L[:-1]) + f\", and {L[-1]}\"\n",
    "\n",
    "\n",
    "def list_to_string(L):\n",
    "    \"\"\"Takes a list of strings and returns a string consisting of every element in the list separated by a newline.\"\"\"\n",
    "    return \"\\n\".join(L)\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    # Split the text by double newlines\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    # Remove leading or trailing whitespacen  and remove empty paragraphs\n",
    "    paragraphs = [p.strip() for p in paragraphs]\n",
    "    paragraphs = [p for p in paragraphs if p]\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def read_queries(filename):\n",
    "    queries = split_text(load_prompt(filename))\n",
    "    queries = [s.strip() for s in queries if not s.strip().startswith('#')]\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT TEMPLATES AND INSTRUCTION PROMPTS\n",
    "\n",
    "\n",
    "dialogue_instruction_prefix = \"\"\"\n",
    "You are going to generate one line of dialogue for a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "Here is a description of the scene in question. {scene_description}{scene_supplement}\\n\n",
    "The characters in the dialogue are {actors}.\n",
    "\"\"\"\n",
    "\n",
    "instruction_template = \"\"\"\n",
    "{preamble}\n",
    "Here is the dialogue so far\\n\\n\n",
    "{dialogue}\n",
    "{instruction_suffix}\n",
    "\"\"\"\n",
    "\n",
    "speech_template = '[{actor}]: {speech}\\n'\n",
    "\n",
    "dialogue_instruction_suffix = \"\"\"\n",
    "Give me the next line in the dialogue in the same format. Don't provide stage directions, just the actor's words.\\n\n",
    "\"\"\"\n",
    "\n",
    "query_preamble_template = \"\"\"\n",
    "{instruction_prefix}\n",
    "This is the game back story. {back_story}\\n\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_prefix = \"\"\"\n",
    "You are going to answer a single question about the current state of the dialogue in a scene in the middle of a computer game.\n",
    "\"\"\"\n",
    "\n",
    "query_instruction_suffix_template = \"\"\"\n",
    "Now consider the following statement about this dialogue. {statement} Is this statement true or false? Answer with a single word, true or false.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING DIALOGUES\n",
    "\n",
    "\n",
    "def prompt_llm(prompt, model):\n",
    "    # print(prompt)\n",
    "    # print()\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt)\n",
    "    chain = prompt | model\n",
    "    return chain\n",
    "\n",
    "\n",
    "def load_prompts(scene_version, supplement_version=-1):\n",
    "    back_story = load_prompt(GAME + \"/back_story.txt\")\n",
    "    scene_description = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_description_\" + str(scene_version) + \".txt\")\n",
    "    if supplement_version == -1:  # no supplementary scene text\n",
    "        scene_supplement = \"\"\n",
    "    else:\n",
    "        scene_supplement = \"\\n\\n\" + load_prompt(\n",
    "            GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_scene_supplement_\" + str(scene_version) + \".txt\")\n",
    "    opening_speech = load_prompt(\n",
    "        GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_opening_speech.txt\")\n",
    "    queries = read_queries(GAME + \"/scenes/\" + SCENE + \"_scene/\" + SCENE + \"_queries.txt\")\n",
    "    return (back_story, scene_description, scene_supplement, opening_speech, queries)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import concurrent\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# Allow loading dialogue middleware packages\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from benchmark import agent_interface\n",
    "from benchmark import dataset_utils\n",
    "from benchmark import dialogue_graph\n",
    "from benchmark import task_runner\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "from iconic_tools import langchain\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dialogue(dialogue_state):\n",
    "    \"\"\"Takes a dialogue state and returns the dialogue itself.\"\"\"\n",
    "    start_tag = \"<chat_history_start>\"\n",
    "    end_tag = \"<chat_history_end>\"\n",
    "    start_index = dialogue_state.find(start_tag)\n",
    "    end_index = dialogue_state.find(end_tag)\n",
    "    if start_index == -1 or end_index == -1:  # tags absent\n",
    "        return None\n",
    "    start_index += len(start_tag)   \n",
    "    dialogue = dialogue_state[start_index:end_index].strip()\n",
    "    return dialogue\n",
    "\n",
    "\n",
    "def extract_role(dialogue_line):\n",
    "    \"\"\"Takes one line of dialogue and returns the character cue.\"\"\"\n",
    "    parts = dialogue_line.split(':', 1)  # split line at the first colon\n",
    "    if len(parts) < 2:  # no colon\n",
    "        return None\n",
    "    return parts[0].strip()\n",
    "\n",
    "\n",
    "def extract_speech(dialogue_line):\n",
    "    \"\"\"Takes one line of dialogue and removes the character cue.\"\"\"\n",
    "    parts = dialogue_line.split(':', 1)  # split line at the first colon\n",
    "    if len(parts) < 2:  # no colon\n",
    "        return None\n",
    "    return parts[1].strip()\n",
    "\n",
    "\n",
    "def strip_brackets(s):\n",
    "    \"\"\"takes a string and replaces every substring of the form '[X]:' with 'X:'.\"\"\"\n",
    "    return re.sub(r'\\[(\\w+)\\]:', r'\\1:', s)\n",
    "\n",
    "\n",
    "def generate_next_line(dialogue_state: str) -> agent_interface.VirtualActorResponse:\n",
    "\n",
    "    (back_story, scene_description, scene_supplement,\n",
    "     opening_speech, queries) = load_prompts(SCENE_VERSION)\n",
    "\n",
    "    dialogue = extract_dialogue(dialogue_state)\n",
    "    dialogue_model = DIALOGUE_MODEL\n",
    "\n",
    "    if dialogue == \"\":\n",
    "        lines = speech_template.format(actor=ACTORS[0], speech=opening_speech)\n",
    "        lines = strip_brackets(lines)\n",
    "        response = extract_speech(lines)\n",
    "        role = ACTORS[0]\n",
    "\n",
    "    else:\n",
    "\n",
    "        dialogue_preamble = preamble_template.format(\n",
    "            instruction_prefix=dialogue_instruction_prefix,\n",
    "            back_story=back_story,\n",
    "            scene_description=scene_description,\n",
    "            scene_supplement=scene_supplement,\n",
    "            actors=list_to_conjunction(ACTORS))\n",
    "        \n",
    "        prompt = instruction_template.format(\n",
    "            preamble=dialogue_preamble, dialogue=dialogue,\n",
    "            instruction_suffix=dialogue_instruction_suffix)\n",
    "        \n",
    "        chain = prompt_llm(prompt, dialogue_model)\n",
    "        lines = chain.invoke({}) + \"\\n\"\n",
    "        response = extract_speech(lines)\n",
    "        role = extract_role(strip_brackets(lines))\n",
    "        \n",
    "    dialogue += lines + \"\\n\"\n",
    "\n",
    "    # Have the conditions for ending the scene been met?\n",
    "    query_preamble = preamble_template.format(\n",
    "        instruction_prefix=query_instruction_prefix,\n",
    "        back_story=back_story,\n",
    "        scene_description=\"\",\n",
    "        scene_supplement=\"\",\n",
    "        actors=list_to_conjunction(ACTORS))\n",
    "    fails = 0\n",
    "    for statement in queries:                \n",
    "        instruction = query_instruction_suffix_template.format(statement=statement)\n",
    "        prompt = instruction_template.format(\n",
    "            preamble=query_preamble, dialogue=dialogue,\n",
    "            instruction_suffix=instruction)\n",
    "        chain = prompt_llm(prompt, dialogue_model)\n",
    "        response = chain.invoke({})\n",
    "        # print(BLUE + \"Statement: {}\".format(statement))\n",
    "        # print(BLUE + \"Result: {}\".format(response))\n",
    "        # print()\n",
    "        if response[0:4] != \"True\" and response[0:3] != \"true\":\n",
    "            fails += 1\n",
    "    success = (fails == 0)\n",
    "\n",
    "    response_dict = {\n",
    "        \"role\": role,\n",
    "        \"text\": response,\n",
    "        \"is_last\": success,\n",
    "    }\n",
    "\n",
    "    return agent_interface.VirtualActorResponse(**response_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]                                   \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:59<00:00, 19.74s/it]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:59<00:00, 19.74s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:50<00:00, 16.88s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:50<00:00, 16.88s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 6/6 [00:50<00:00,  8.44s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:50<00:00, 16.88s/it]\n",
      " 40%|████      | 2/5 [01:01<01:38, 32.85s/it]\n",
      "100%|██████████| 2/2 [00:59<00:00, 29.62s/it]\n",
      "\n",
      "\n",
      "100%|██████████| 2/2 [00:59<00:00, 29.62s/it]\n",
      "100%|██████████| 5/5 [01:01<00:00, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_idx: 0\n",
      "task: emotions\n",
      "score: 0.1111111111111111\n",
      "synergy_impersonation_score: 0.16666666666666666\n",
      "exec_seconds: 91.57588386535645\n",
      "precision: 0\n",
      "synergy_Corky: 0\n",
      "impersonation_Corky: 0.0\n",
      "synergy_Violet: 0.3333333333333333\n",
      "impersonation_Violet: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metric_llm = langchain.InstructGPT4(temperature=0, max_tokens=4096)\n",
    "\n",
    "(dialogue, dialogue_state) = dataset_utils.load_scene(GENRE, GAME, SCENE_IDX)\n",
    "\n",
    "facts = [list_to_string(dialogue.facts)]\n",
    "comm_style = [list_to_string(dialogue.comm_style)]\n",
    "goals = [list_to_string(dialogue.goals)]\n",
    "\n",
    "initial_state = dialogue_graph.Dialogue(facts=facts, comm_style=comm_style, goals=goals)\n",
    "\n",
    "# Run the evaluation\n",
    "results = await task_runner.eval_agent(\n",
    "    task_idx=0, \n",
    "    task=dataset_utils.Tasks.EMOTIONS, \n",
    "    initial_state=initial_state, \n",
    "    agent=generate_next_line, \n",
    "    metric_calc_llm=metric_llm)\n",
    "\n",
    "# Print out the results\n",
    "results_dict = dict(results)\n",
    "for key in results_dict.keys():\n",
    "    print(key + \": \" + str(results_dict[key][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_idx: 0\n",
      "task: emotions\n",
      "score: 0.1111111111111111\n",
      "synergy_impersonation_score: 0.16666666666666666\n",
      "exec_seconds: 91.57588386535645\n",
      "precision: 0\n",
      "synergy_Corky: 0\n",
      "impersonation_Corky: 0.0\n",
      "synergy_Violet: 0.3333333333333333\n",
      "impersonation_Violet: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "results_dict = dict(results)\n",
    "for key in results_dict.keys():\n",
    "    print(key + \": \" + str(results_dict[key][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMvenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
